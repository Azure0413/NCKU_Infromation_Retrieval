{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqKU6ckCDnD3",
        "outputId": "a25a7cd0-d826-4ada-c40b-337452799b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 39256625 saved to pubmed_xml2/39256625.xml\n",
            "Article 39255289 saved to pubmed_xml2/39255289.xml\n",
            "Article 39253236 saved to pubmed_xml2/39253236.xml\n",
            "Article 39250110 saved to pubmed_xml2/39250110.xml\n",
            "Article 39248619 saved to pubmed_xml2/39248619.xml\n",
            "Article 39245678 saved to pubmed_xml2/39245678.xml\n",
            "Article 39244512 saved to pubmed_xml2/39244512.xml\n",
            "Article 39243017 saved to pubmed_xml2/39243017.xml\n",
            "Article 39242659 saved to pubmed_xml2/39242659.xml\n",
            "Article 39241940 saved to pubmed_xml2/39241940.xml\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "from xml.etree import ElementTree\n",
        "\n",
        "def fetch_pubmed_xml(query, max_results=10, output_dir=\"output\", batch_size=5, sleep_time=1):\n",
        "    # Base URL for Entrez E-utilities\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "\n",
        "    # Step 1: Use ESearch to get the list of PubMed IDs (PMIDs) for the query\n",
        "    search_url = f\"{base_url}esearch.fcgi\"\n",
        "    search_params = {\n",
        "        \"db\": \"pubmed\",\n",
        "        \"term\": query,\n",
        "        \"retmax\": max_results,\n",
        "        \"retmode\": \"xml\"\n",
        "    }\n",
        "\n",
        "    search_response = requests.get(search_url, params=search_params)\n",
        "    search_response.raise_for_status()\n",
        "    search_xml = ElementTree.fromstring(search_response.content)\n",
        "\n",
        "    # Extract PMIDs from the search results\n",
        "    pmids = [id_elem.text for id_elem in search_xml.findall(\".//Id\")]\n",
        "\n",
        "    if not pmids:\n",
        "        print(\"No results found.\")\n",
        "        return\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Step 2: Fetch articles in batches to avoid rate limiting\n",
        "    fetch_url = f\"{base_url}efetch.fcgi\"\n",
        "    for i in range(0, len(pmids), batch_size):\n",
        "        # Split PMIDs into batches\n",
        "        batch_pmids = pmids[i:i + batch_size]\n",
        "        fetch_params = {\n",
        "            \"db\": \"pubmed\",\n",
        "            \"id\": \",\".join(batch_pmids),\n",
        "            \"retmode\": \"xml\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            fetch_response = requests.get(fetch_url, params=fetch_params)\n",
        "            fetch_response.raise_for_status()\n",
        "\n",
        "            # Split fetched XML data and save each article by PMID\n",
        "            articles = ElementTree.fromstring(fetch_response.content).findall(\".//PubmedArticle\")\n",
        "            for article in articles:\n",
        "                pmid = article.find(\".//PMID\").text\n",
        "                file_path = os.path.join(output_dir, f\"{pmid}.xml\")\n",
        "\n",
        "                with open(file_path, 'wb') as file:\n",
        "                    file.write(ElementTree.tostring(article, encoding='utf-8'))\n",
        "\n",
        "                print(f\"Article {pmid} saved to {file_path}\")\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            print(f\"Failed to fetch batch {i+1} due to {e}\")\n",
        "\n",
        "        # Sleep to avoid hitting the rate limit\n",
        "        time.sleep(sleep_time)\n",
        "\n",
        "# Example usage:\n",
        "query = \"cybersecurity\"\n",
        "max_results = 10  # Set the number of articles to download\n",
        "output_directory = \"pubmed_xml2\"  # Set your desired output directory\n",
        "batch_size = 5  # Number of articles to fetch in each batch\n",
        "sleep_time = 0.1  # Time in seconds to sleep between batches\n",
        "fetch_pubmed_xml(query, max_results, output_directory, batch_size, sleep_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFt6J8fwFd06"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}