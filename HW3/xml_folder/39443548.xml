<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">39443548</PMID><DateCompleted><Year>2024</Year><Month>10</Month><Day>24</Day></DateCompleted><DateRevised><Year>2024</Year><Month>10</Month><Day>27</Day></DateRevised><Article PubModel="Electronic"><Journal><ISSN IssnType="Electronic">2045-2322</ISSN><JournalIssue CitedMedium="Internet"><Volume>14</Volume><Issue>1</Issue><PubDate><Year>2024</Year><Month>Oct</Month><Day>23</Day></PubDate></JournalIssue><Title>Scientific reports</Title><ISOAbbreviation>Sci Rep</ISOAbbreviation></Journal><ArticleTitle>Integrated ensemble CNN and explainable AI for COVID-19 diagnosis from CT scan and X-ray images.</ArticleTitle><Pagination><StartPage>24985</StartPage><MedlinePgn>24985</MedlinePgn></Pagination><ELocationID EIdType="pii" ValidYN="Y">24985</ELocationID><ELocationID EIdType="doi" ValidYN="Y">10.1038/s41598-024-75915-y</ELocationID><Abstract><AbstractText>In light of the ongoing battle against COVID-19, while the pandemic may eventually subside, sporadic cases may still emerge, underscoring the need for accurate detection from radiological images. However, the limited explainability of current deep learning models restricts clinician acceptance. To address this issue, our research integrates multiple CNN models with explainable AI techniques, ensuring model interpretability before ensemble construction. Our approach enhances both accuracy and interpretability by evaluating advanced CNN models on the largest publicly available X-ray dataset, COVIDx CXR-3, which includes 29,986 images, and the CT scan dataset for SARS-CoV-2 from Kaggle, which includes a total of 2,482 images. We also employed additional public datasets for cross-dataset evaluation, ensuring a thorough assessment of model performance across various imaging conditions. By leveraging methods including LIME, SHAP, Grad-CAM, and Grad-CAM++, we provide transparent insights into model decisions. Our ensemble model, which includes DenseNet169, ResNet50, and VGG16, demonstrates strong performance. For the X-ray image dataset, sensitivity, specificity, accuracy, F1-score, and AUC are recorded at 99.00%, 99.00%, 99.00%, 0.99, and 0.99, respectively. For the CT image dataset, these metrics are 96.18%, 96.18%, 96.18%, 0.9618, and 0.96, respectively. Our methodology bridges the gap between precision and interpretability in clinical settings by combining model diversity with explainability, promising enhanced disease diagnosis and greater clinician acceptance.</AbstractText><CopyrightInformation>© 2024. The Author(s).</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Rajpoot</LastName><ForeName>Reenu</ForeName><Initials>R</Initials><AffiliationInfo><Affiliation>Department of Computer Science and Engineering, Maulana Azad National Institute of Technology, Bhopal, 462003, India. rajputreenu@gmail.com.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Gour</LastName><ForeName>Mahesh</ForeName><Initials>M</Initials><AffiliationInfo><Affiliation>Department of Computer Science and Engineering, Maulana Azad National Institute of Technology, Bhopal, 462003, India.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Jain</LastName><ForeName>Sweta</ForeName><Initials>S</Initials><AffiliationInfo><Affiliation>Department of Computer Science and Engineering, Maulana Azad National Institute of Technology, Bhopal, 462003, India.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Semwal</LastName><ForeName>Vijay Bhaskar</ForeName><Initials>VB</Initials><AffiliationInfo><Affiliation>Department of Computer Science and Engineering, Maulana Azad National Institute of Technology, Bhopal, 462003, India.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2024</Year><Month>10</Month><Day>23</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>Sci Rep</MedlineTA><NlmUniqueID>101563288</NlmUniqueID><ISSNLinking>2045-2322</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000086382" MajorTopicYN="Y">COVID-19</DescriptorName><QualifierName UI="Q000000981" MajorTopicYN="N">diagnostic imaging</QualifierName><QualifierName UI="Q000175" MajorTopicYN="N">diagnosis</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D014057" MajorTopicYN="Y">Tomography, X-Ray Computed</DescriptorName><QualifierName UI="Q000379" MajorTopicYN="N">methods</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D000077321" MajorTopicYN="Y">Deep Learning</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000086402" MajorTopicYN="Y">SARS-CoV-2</DescriptorName><QualifierName UI="Q000302" MajorTopicYN="N">isolation &amp; purification</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D016571" MajorTopicYN="N">Neural Networks, Computer</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">COVID-19</Keyword><Keyword MajorTopicYN="N">CT scan images</Keyword><Keyword MajorTopicYN="N">Chest X-ray images</Keyword><Keyword MajorTopicYN="N">Convolutional neural networks (CNN)</Keyword><Keyword MajorTopicYN="N">Deep learning</Keyword><Keyword MajorTopicYN="N">Ensemble</Keyword><Keyword MajorTopicYN="N">Explainable AI</Keyword></KeywordList><CoiStatement>The authors declare no competing interests.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>5</Month><Day>8</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>10</Month><Day>9</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>10</Month><Day>24</Day><Hour>16</Hour><Minute>22</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>10</Month><Day>24</Day><Hour>16</Hour><Minute>21</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>10</Month><Day>24</Day><Hour>0</Hour><Minute>2</Minute></PubMedPubDate><PubMedPubDate PubStatus="pmc-release"><Year>2024</Year><Month>10</Month><Day>23</Day></PubMedPubDate></History><PublicationStatus>epublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39443548</ArticleId><ArticleId IdType="pmc">PMC11499875</ArticleId><ArticleId IdType="doi">10.1038/s41598-024-75915-y</ArticleId><ArticleId IdType="pii">10.1038/s41598-024-75915-y</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>World Health Organization. Coronavirus disease (covid-19): Post-covid-19 condition. https://www.who.int/health-topics/coronavirus. Accessed: 2024-02-07.</Citation></Reference><Reference><Citation>Fang, Y. et al. Sensitivity of chest CT for COVID-19: comparison to RT-PCR. Radiology 296(2), E115–E117 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7233365</ArticleId><ArticleId IdType="pubmed">32073353</ArticleId></ArticleIdList></Reference><Reference><Citation>Ai, T. et al. Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in China: a report of 1014 cases. Radiology 296(2), E32–E40 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7233399</ArticleId><ArticleId IdType="pubmed">32101510</ArticleId></ArticleIdList></Reference><Reference><Citation>Ng, M. Y. et al. Imaging profile of the covid-19 infection: radiologic findings and literature review. Radiol. Cardiothorac. Imaging2(1), e200034 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7233595</ArticleId><ArticleId IdType="pubmed">33778547</ArticleId></ArticleIdList></Reference><Reference><Citation>Kanne, J. P., Little, B. P., Chung, J. H., Elicker, B. M. &amp; Ketai, L. H. Essentials for radiologists on covid-19: an update—radiology scientific expert panel. Radiology 296(2), E113–E114 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7233379</ArticleId><ArticleId IdType="pubmed">32105562</ArticleId></ArticleIdList></Reference><Reference><Citation>Zhang, J. et al. Recent developments in segmentation of covid-19 ct images using deep-learning: an overview of models, techniques and challenges. Biomed. Signal. Process. Control. 91. 10.1016/j.bspc.2024.105970 (2024).</Citation></Reference><Reference><Citation>Dai, H., Yang, Y., Yue, X. &amp; Chen, S. Improving retinal oct image classification accuracy using medical pre-training and sample replication methods. Biomed. Signal. Process. Control. 91. 10.1016/j.bspc.2024.106019 (2024).</Citation></Reference><Reference><Citation>Zhang, L. et al. Deep learning model based on primary tumor to predict lymph node status in clinical stage ia lung adenocarcinoma: a multicenter study. J. Natl. Cancer Cent.. 10.1016/j.jncc.2024.01.005 (2024).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC11401490</ArticleId><ArticleId IdType="pubmed">39281718</ArticleId></ArticleIdList></Reference><Reference><Citation>Mary, A. R. &amp; Kavitha, P. Diabetic retinopathy disease detection using shapley additive ensembled densenet-121 resnet-50 model. Multimed Tools Appl. 1–28. 10.1007/s11042-024-18309-6 (2024).</Citation></Reference><Reference><Citation>Nehru, V. &amp; Prabhu, V. Automated multimodal brain tumor segmentation and localization in mri images using hybrid res2-unext. J. Electr. Eng. Technol. 1–13. 10.1007/s42835-023-01779-3 (2024).</Citation></Reference><Reference><Citation>Pathan, S., Kumar, P., Pai, R. M. &amp; Bhandary, S. V. An automated classification framework for glaucoma detection in fundus images using ensemble of dynamic selection methods. Prog Artif. Intell.12, 287–301. 10.1007/s13748-023-00304-x (2023).</Citation></Reference><Reference><Citation>Simonyan, K. &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).</Citation></Reference><Reference><Citation>He, K., Zhang, X., Ren, S. &amp; Sun, J. Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE Trans. Pattern Anal. Mach. Intell.37, 1904–1916. 10.1109/TPAMI.2015.2389824 (2015).</Citation><ArticleIdList><ArticleId IdType="pubmed">26353135</ArticleId></ArticleIdList></Reference><Reference><Citation>Huang, G., Liu, Z., Pleiss, G., Van Der Maaten, L. &amp; Weinberger, K. Q. Convolutional networks with dense connectivity. IEEE Trans. Pattern Anal. Mach. Intell.44, 8704–8716. 10.1109/TPAMI.2019.2918284 (2019).</Citation><ArticleIdList><ArticleId IdType="pubmed">31135351</ArticleId></ArticleIdList></Reference><Reference><Citation>Tan, M., Le, Q. &amp; Efficientnet Rethinking model scaling for convolutional neural networks. In International conference on machine learning, 6105–6114.  10.48550/arXiv.1905.11946 (2019).</Citation></Reference><Reference><Citation>Chollet, F. &amp; Xception Deep learning with depthwise separable convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1251–1258. 10.48550/arXiv.1610.02357 (2017).</Citation></Reference><Reference><Citation>Ribeiro, M. T., Singh, S. &amp; Guestrin, C. Why should i trust you? explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 1135–1144.  10.1145/2939672.2939778 (2016).</Citation></Reference><Reference><Citation>Lundberg, S. M. &amp; Lee, S. I. A unified approach to interpreting model predictions. Adv. Neural Inform. Process. Syst.30. 10.48550/arXiv.1705.07874 (2017).</Citation></Reference><Reference><Citation>Selvaraju, R. R. et al. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision, 618–626. 10.1007/s11263-019-01228-7 (2017).</Citation></Reference><Reference><Citation>Chattopadhay, A., Sarkar, A., Howlader, P. &amp; Balasubramanian, V. N. Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks. In IEEE winter conference on applications of computer vision (WACV), 839–847. 10.1109/WACV.2018.00097 (IEEE, 2018).</Citation></Reference><Reference><Citation>Prinzi, F., Militello, C., Scichilone, N., Gaglio, S. &amp; Vitabile, S. Explainable machine-learning models for covid-19 prognosis prediction using clinical, laboratory and radiomic features. IEEE Access11, 121492–121510. 10.1109/ACCESS.2023.3327808 (2023).</Citation></Reference><Reference><Citation>Soda, P. et al. Aiforcovid: Predicting the clinical outcomes in patients with covid-19 applying ai to chest-x-rays. An Italian multicentre study. Med. Image Anal.74. 10.1016/j.media.2021.102216 (2021).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC8401374</ArticleId><ArticleId IdType="pubmed">34492574</ArticleId></ArticleIdList></Reference><Reference><Citation>Sun, Y. et al. Use of machine learning to assess the prognostic utility of radiomic features for in-hospital covid-19 mortality. Sci. Rep.13. 10.1038/s41598-023-34559-0 (2023).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10161188</ArticleId><ArticleId IdType="pubmed">37147440</ArticleId></ArticleIdList></Reference><Reference><Citation>Abubakar, H., Al-Turjman, F., Ameen, Z. S., Mubarak, A. S. &amp; Alturjman, C. A hybridized feature extraction for covid-19 multi-class classification on computed tomography images. Heliyon. 10.1016/j.heliyon.2024.e26939 (2024).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10920381</ArticleId><ArticleId IdType="pubmed">38463848</ArticleId></ArticleIdList></Reference><Reference><Citation>Ragab, D. A., Fayed, S., Ghatwary, N. &amp; Deepcsfusion Deep compressive sensing fusion for efficient covid-19 classification. J. Imaging Inf. Med.1–13. 10.1007/s10278-024-01011-2 (2024).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC11300776</ArticleId><ArticleId IdType="pubmed">38381386</ArticleId></ArticleIdList></Reference><Reference><Citation>Haynes, S. C., Johnston, P. &amp; Elyan, E. Generalisation challenges in deep learning models for medical imagery: insights from external validation of covid-19 classifiers. Multimed Tools Appl. 1–20. 10.1007/s11042-024-18543-y (2024).</Citation></Reference><Reference><Citation>Suhartanto, H. et al. Scov-cnn: a simple cnn architecture for covid-19 identification based on the ct images. JOIV: Int. J. Inf. Vis.8. 10.62527/joiv.8.1.1750 (2024).</Citation></Reference><Reference><Citation>Zhao, A., Wu, H., Chen, M. &amp; Wang, N. A multi-level feature attention network for covid-19 detection based on multi-source medical images. Multimed Tools Appl. 1–32. 10.1007/s11042-023-18014-w (2024).</Citation></Reference><Reference><Citation>Abdellatef, E. &amp; Allah, M. F. Hybrid whale optimization and canonical correlation based covid-19 classification approach. Multimed Tools Appl. 1–22. 10.1007/s11042-024-18153-8 (2024).</Citation></Reference><Reference><Citation>Hoffer, O. et al. Smartphone-based detection of covid-19 and associated pneumonia using thermal imaging and a transfer learning algorithm. J. Biophotonics. e202300486. 10.1002/jbio.202300486 (2024).</Citation><ArticleIdList><ArticleId IdType="pubmed">38253344</ArticleId></ArticleIdList></Reference><Reference><Citation>Sanampudi, A. &amp; Srinivasan, S. Local search enhanced optimal inception-resnet-v2 for classification of long-term lung diseases in post-covid-19 patients. Automatika. 65, 473–482. 10.1080/00051144.2023.2295142 (2024).</Citation></Reference><Reference><Citation>Zafar, A. et al. Robust medical diagnosis: a novel two-phase deep learning framework for adversarial proof disease detection in radiology images. J. Imaging Inf. Med.1–31. 10.1007/s10278-023-00916-8 (2024).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC11266337</ArticleId><ArticleId IdType="pubmed">38343214</ArticleId></ArticleIdList></Reference><Reference><Citation>Türk, F. &amp; Kökver, Y. Detection of lung opacity and treatment planning with three-channel fusion cnn model. Arab. J. Sci. Eng. 1–13. 10.1007/s13369-023-07843-4 (2023).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10103673</ArticleId><ArticleId IdType="pubmed">37361471</ArticleId></ArticleIdList></Reference><Reference><Citation>Saheb, S. K., Narayanan, B. &amp; Rao, T. V. N. Adl-cdf: a deep learning framework for covid-19 detection from ct scans towards an automated clinical decision support system. Arab. J. Sci. Eng.48, 9661–9673. 10.1007/ s13369-022-07271-w (2023).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC9531859</ArticleId><ArticleId IdType="pubmed">36212631</ArticleId></ArticleIdList></Reference><Reference><Citation>Holzinger, A., Biemann, C., Pattichis, C. S. &amp; Kell, D. B. What do we need to build explainable ai systems for the medical domain? arXiv Preprint arXiv:1712 09923. 10.48550/arXiv.1712.09923 (2017).</Citation></Reference><Reference><Citation>Koul, A., Bawa, R. K. &amp; Kumar, Y. Enhancing the detection of airway disease by applying deep learning and explainable artificial intelligence. Multimed Tools Appl. 1–33. 10.1007/s11042-024-18381-y (2024).</Citation></Reference><Reference><Citation>Chadaga, K. et al. A decision support system for diagnosis of covid-19 from non-covid-19 influenza-like illness using explainable artificial intelligence. Bioengineering. 10, 439. 10.3390/bioengineering10040439 (2023).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10135993</ArticleId><ArticleId IdType="pubmed">37106626</ArticleId></ArticleIdList></Reference><Reference><Citation>He, K., Zhang, X., Ren, S. &amp; Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–778. 10.48550/arXiv.1512.03385 (2016).</Citation></Reference><Reference><Citation>Huang, G., Liu, Z., Van Der Maaten, L. &amp; Weinberger, K. Q. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 4700–4708. 10.48550/arXiv.1608.06993 (2017).</Citation></Reference><Reference><Citation>Soares, E., Angelov, P., Biaso, S., Froes, M. H. &amp; Abe, D. K. Sars-cov-2 ct-scan dataset: a large dataset of real patients ct scans for sars-cov-2 identification. MedRxiv. 10.1101/2020.04.24.20078584 (2020).</Citation><ArticleIdList><ArticleId IdType="pubmed">0</ArticleId></ArticleIdList></Reference><Reference><Citation>Pavlova, M. et al. Covid-net cxr-2: an enhanced deep convolutional neural network design for detection of covid-19 cases from chest x-ray images. Front. Med.9. 10.3389/fmed.2022.861680 (2022).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC9226387</ArticleId><ArticleId IdType="pubmed">35755067</ArticleId></ArticleIdList></Reference><Reference><Citation>Maftouni, M. et al. A robust ensemble-deep learning model for covid-19 diagnosis based on an integrated ct scan images database. In IIE annual conference. Proceedings, 632–637 (Institute of Industrial and Systems Engineers (IISE), (2021).</Citation></Reference><Reference><Citation>Rahman, T. &amp; collaborators. COVID-19 Chest X-Ray Database. (2022). https://www.kaggle.com/tawsifurrahman/covid19-radiography-database Accessed: 2024-08-11.</Citation></Reference><Reference><Citation>Zou, L. et al. Ensemble image explainable ai (xai) algorithm for severe community-acquired pneumonia and covid-19 respiratory infections. IEEE Trans. Artif. Intell.4, 242–254. 10.1109/TAI.2022.3153754 (2022).</Citation></Reference><Reference><Citation>Liu, Z., Shen, L. &amp; Cect Controllable ensemble cnn and transformer for covid-19 image classification. Comput. Biol. Med.173. 10.1016/j.compbiomed.2024.108388 (2024).</Citation><ArticleIdList><ArticleId IdType="pubmed">38569235</ArticleId></ArticleIdList></Reference><Reference><Citation>Dey, S. et al. A fuzzy ensemble model for covid-19 detection from chest x-rays. Expert Syst. Appl.206. 10.1016/j.eswa.2022.117812 (2022).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC9212804</ArticleId><ArticleId IdType="pubmed">35754941</ArticleId></ArticleIdList></Reference><Reference><Citation>Eshraghi, M. A., Ayatollahi, A. &amp; Shokouhi, S. B. Cov-mobnets: a mobile networks ensemble model for diagnosis of covid-19 based on chest x-ray images. BMC Med. Imaging. 23, 83. 10.1186/s12880-023-01039-w (2023).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10273540</ArticleId><ArticleId IdType="pubmed">37322450</ArticleId></ArticleIdList></Reference><Reference><Citation>Abad, M., Casas-Roma, J. &amp; Prados, F. Generalizable disease detection using model ensemble on chest x-ray images. Sci. Rep.14. 10.1038/s41598-024-56171-6 (2024).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10928229</ArticleId><ArticleId IdType="pubmed">38467705</ArticleId></ArticleIdList></Reference><Reference><Citation>Panwar, H. et al. A deep learning and grad-cam based color visualization approach for fast detection of covid-19 cases using chest x-ray and ct-scan images. Chaos Solitons Fractals. 140, 110190. 10.1016/j.chaos.2020.110190 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7413068</ArticleId><ArticleId IdType="pubmed">32836918</ArticleId></ArticleIdList></Reference><Reference><Citation>Silva, P. et al. Covid-19 detection in ct images with deep learning: a voting-based scheme and cross-datasets analysis. Inf. Med. Unlocked. 20. 10.1016/j.imu.2020.100427 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7487744</ArticleId><ArticleId IdType="pubmed">32953971</ArticleId></ArticleIdList></Reference><Reference><Citation>Yang, D. et al. Detection and analysis of covid-19 in medical images using deep learning techniques. Sci. Rep.11. 10.1038/s41598-021-99015-3 (2021).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC8490426</ArticleId><ArticleId IdType="pubmed">34608186</ArticleId></ArticleIdList></Reference></ReferenceList></PubmedData></PubmedArticle>