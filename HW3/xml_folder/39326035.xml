<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">39326035</PMID><DateCompleted><Year>2024</Year><Month>09</Month><Day>26</Day></DateCompleted><DateRevised><Year>2024</Year><Month>10</Month><Day>13</Day></DateRevised><Article PubModel="Electronic"><Journal><ISSN IssnType="Electronic">2564-1891</ISSN><JournalIssue CitedMedium="Internet"><Volume>4</Volume><PubDate><Year>2024</Year><Month>Sep</Month><Day>26</Day></PubDate></JournalIssue><Title>JMIR infodemiology</Title><ISOAbbreviation>JMIR Infodemiology</ISOAbbreviation></Journal><ArticleTitle>Evaluating the Influence of Role-Playing Prompts on ChatGPT's Misinformation Detection Accuracy: Quantitative Study.</ArticleTitle><Pagination><StartPage>e60678</StartPage><MedlinePgn>e60678</MedlinePgn></Pagination><ELocationID EIdType="pii" ValidYN="Y">e60678</ELocationID><ELocationID EIdType="doi" ValidYN="Y">10.2196/60678</ELocationID><Abstract><AbstractText Label="BACKGROUND" NlmCategory="BACKGROUND">During the COVID-19 pandemic, the rapid spread of misinformation on social media created significant public health challenges. Large language models (LLMs), pretrained on extensive textual data, have shown potential in detecting misinformation, but their performance can be influenced by factors such as prompt engineering (ie, modifying LLM requests to assess changes in output). One form of prompt engineering is role-playing, where, upon request, OpenAI's ChatGPT imitates specific social roles or identities. This research examines how ChatGPT's accuracy in detecting COVID-19-related misinformation is affected when it is assigned social identities in the request prompt. Understanding how LLMs respond to different identity cues can inform messaging campaigns, ensuring effective use in public health communications.</AbstractText><AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">This study investigates the impact of role-playing prompts on ChatGPT's accuracy in detecting misinformation. This study also assesses differences in performance when misinformation is explicitly stated versus implied, based on contextual knowledge, and examines the reasoning given by ChatGPT for classification decisions.</AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">Overall, 36 real-world tweets about COVID-19 collected in September 2021 were categorized into misinformation, sentiment (opinions aligned vs unaligned with public health guidelines), corrections, and neutral reporting. ChatGPT was tested with prompts incorporating different combinations of multiple social identities (ie, political beliefs, education levels, locality, religiosity, and personality traits), resulting in 51,840 runs. Two control conditions were used to compare results: prompts with no identities and those including only political identity.</AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">The findings reveal that including social identities in prompts reduces average detection accuracy, with a notable drop from 68.1% (SD 41.2%; no identities) to 29.3% (SD 31.6%; all identities included). Prompts with only political identity resulted in the lowest accuracy (19.2%, SD 29.2%). ChatGPT was also able to distinguish between sentiments expressing opinions not aligned with public health guidelines from misinformation making declarative statements. There were no consistent differences in performance between explicit and implicit misinformation requiring contextual knowledge. While the findings show that the inclusion of identities decreased detection accuracy, it remains uncertain whether ChatGPT adopts views aligned with social identities: when assigned a conservative identity, ChatGPT identified misinformation with nearly the same accuracy as it did when assigned a liberal identity. While political identity was mentioned most frequently in ChatGPT's explanations for its classification decisions, the rationales for classifications were inconsistent across study conditions, and contradictory explanations were provided in some instances.</AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">These results indicate that ChatGPT's ability to classify misinformation is negatively impacted when role-playing social identities, highlighting the complexity of integrating human biases and perspectives in LLMs. This points to the need for human oversight in the use of LLMs for misinformation detection. Further research is needed to understand how LLMs weigh social identities in prompt-based tasks and explore their application in different cultural contexts.</AbstractText><CopyrightInformation>©Michael Robert Haupt, Luning Yang, Tina Purnat, Tim Mackey. Originally published in JMIR Infodemiology (https://infodemiology.jmir.org), 26.09.2024.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y" EqualContrib="Y"><LastName>Haupt</LastName><ForeName>Michael Robert</ForeName><Initials>MR</Initials><Identifier Source="ORCID">0000-0003-4985-7796</Identifier><AffiliationInfo><Affiliation>Department of Cognitive Science, University of California, San Diego, La Jolla, CA, United States.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Global Health Program, Department of Anthropology, University of California, San Diego, La Jolla, CA, United States.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Global Health Policy &amp; Data Institute, San Diego, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y" EqualContrib="Y"><LastName>Yang</LastName><ForeName>Luning</ForeName><Initials>L</Initials><Identifier Source="ORCID">0009-0006-4876-591X</Identifier><AffiliationInfo><Affiliation>Global Health Policy &amp; Data Institute, San Diego, CA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Purnat</LastName><ForeName>Tina</ForeName><Initials>T</Initials><Identifier Source="ORCID">0000-0002-0257-6631</Identifier><AffiliationInfo><Affiliation>TH Chan School of Public Health, Harvard University, Boston, MA, United States.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Mackey</LastName><ForeName>Tim</ForeName><Initials>T</Initials><Identifier Source="ORCID">0000-0002-2191-7833</Identifier><AffiliationInfo><Affiliation>Global Health Program, Department of Anthropology, University of California, San Diego, La Jolla, CA, United States.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Global Health Policy &amp; Data Institute, San Diego, CA, United States.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>S-3 Research, San Diego, CA, United States.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2024</Year><Month>09</Month><Day>26</Day></ArticleDate></Article><MedlineJournalInfo><Country>Canada</Country><MedlineTA>JMIR Infodemiology</MedlineTA><NlmUniqueID>9918249014806676</NlmUniqueID><ISSNLinking>2564-1891</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000086382" MajorTopicYN="Y">COVID-19</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D003142" MajorTopicYN="Y">Communication</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D061108" MajorTopicYN="Y">Social Media</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D012381" MajorTopicYN="Y">Role Playing</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D058873" MajorTopicYN="N">Pandemics</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000086402" MajorTopicYN="N">SARS-CoV-2</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D011634" MajorTopicYN="N">Public Health</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">AI</Keyword><Keyword MajorTopicYN="N">COVID-19</Keyword><Keyword MajorTopicYN="N">ChatGPT</Keyword><Keyword MajorTopicYN="N">artificial intelligence</Keyword><Keyword MajorTopicYN="N">experiment</Keyword><Keyword MajorTopicYN="N">large language models</Keyword><Keyword MajorTopicYN="N">misinformation detection</Keyword><Keyword MajorTopicYN="N">prompt engineering</Keyword><Keyword MajorTopicYN="N">role-playing</Keyword><Keyword MajorTopicYN="N">social identity</Keyword></KeywordList><CoiStatement>Conflicts of Interest: TM is an employee of, and holds equity in, the company S-3 Research LLC; he is also the editor-in-chief of <i>JMIR Infodemiology</i>. TP and MRH are associate editors of <i>JMIR Infodemilogy</i>. LY declares no conflict of interest.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>5</Month><Day>17</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>8</Month><Day>12</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2024</Year><Month>7</Month><Day>19</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>9</Month><Day>26</Day><Hour>19</Hour><Minute>4</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>9</Month><Day>26</Day><Hour>19</Hour><Minute>3</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>9</Month><Day>26</Day><Hour>16</Hour><Minute>52</Minute></PubMedPubDate><PubMedPubDate PubStatus="pmc-release"><Year>2024</Year><Month>9</Month><Day>26</Day></PubMedPubDate></History><PublicationStatus>epublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39326035</ArticleId><ArticleId IdType="pmc">PMC11467603</ArticleId><ArticleId IdType="doi">10.2196/60678</ArticleId><ArticleId IdType="pii">v4i1e60678</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Zarocostas J. How to fight an infodemic. Lancet. 2020 Feb;395(10225):676. doi: 10.1016/s0140-6736(20)30461-x.</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/s0140-6736(20)30461-x</ArticleId><ArticleId IdType="pmc">PMC7133615</ArticleId><ArticleId IdType="pubmed">32113495</ArticleId></ArticleIdList></Reference><Reference><Citation>Ajao O, Bhowmik D, Zargari S. Sentiment aware fake news detection on online social networks. Proceedings of the 2019 IEEE International Conference on Acoustics, Speech and Signal Processing; ICASSP '19; May 12-17, 2019; Brighton, UK. 2019. pp. 2507–11. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/icassp.2019.8683170</ArticleId></ArticleIdList></Reference><Reference><Citation>Bhutani B, Rastogi N, Sehgal P, Purwar A. Fake news detection using sentiment analysis. Proceedings of the 12th International Conference on Contemporary Computing; IC3D '19; August 8-10, 2019; Noida, India. 2019. pp. 1–5. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/ic3.2019.8844880</ArticleId></ArticleIdList></Reference><Reference><Citation>Caramancion KM. Harnessing the power of ChatGPT to decimate mis/disinformation: using chatgpt for fake news detection. Proceedings of the 2023 IEEE World AI IoT Congress; AIIoT '23; June 7-10, 2023; Seattle, WA. 2023. p. 6. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/aiiot58121.2023.10174450</ArticleId></ArticleIdList></Reference><Reference><Citation>Johnson SB, King AJ, Warner EL, Aneja S, Kann BH, Bylund CL. Using ChatGPT to evaluate cancer myths and misconceptions: artificial intelligence and cancer information. JNCI Cancer Spectr. 2023 Mar 01;7(2):pkad015. doi: 10.1093/jncics/pkad015. 
 
7078555</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/jncics/pkad015</ArticleId><ArticleId IdType="pmc">PMC10020140</ArticleId><ArticleId IdType="pubmed">36929393</ArticleId></ArticleIdList></Reference><Reference><Citation>Kolluri N, Liu Y, Murthy D. COVID-19 misinformation detection: machine-learned solutions to the infodemic. JMIR Infodemiology. 2022 Aug 25;2(2):e38756. doi: 10.2196/38756. 
 
v2i2e38756</Citation><ArticleIdList><ArticleId IdType="doi">10.2196/38756</ArticleId><ArticleId IdType="pmc">PMC9987189</ArticleId><ArticleId IdType="pubmed">37113446</ArticleId></ArticleIdList></Reference><Reference><Citation>Lee CJ, Chua HN. Using linguistics and psycholinguistics features in machine learning for fake news classification through Twitter. Proceedings of the 2021 International Conference on Data Science and Applications; ICDSA '21; April 10-11, 2021; Kolkata, India. 2021. pp. 717–30. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/978-981-16-5120-5_54</ArticleId><ArticleId IdType="doi">10.1007/978-981-16-5120-5_54</ArticleId></ArticleIdList></Reference><Reference><Citation>Naveed H, Khan AU, Qiu S, Saqib M, Anwar S, Usman M, Akhtar N, Barnes N, Milan A. A comprehensive overview of large language models. arXiv. Preprint posted online July 12, 2023.  doi: 10.48550/arXiv.2307.06435. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.48550/arXiv.2307.06435</ArticleId></ArticleIdList></Reference><Reference><Citation>Firth JR. A Synopsis of Linguistic Theory, 1930-1955. Oxfordshire, UK: Blackwell Publishing; 1957.</Citation></Reference><Reference><Citation>King MR, chatGPT  A conversation on artificial intelligence, chatbots, and plagiarism in higher education. Cell Mol Bioeng. 2023 Feb 02;16(1):1–2. doi: 10.1007/s12195-022-00754-8. 
 
754</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/s12195-022-00754-8</ArticleId><ArticleId IdType="pmc">PMC9842816</ArticleId><ArticleId IdType="pubmed">36660590</ArticleId></ArticleIdList></Reference><Reference><Citation>De Angelis L, Baglivo F, Arzilli G, Privitera GP, Ferragina P, Tozzi AE, Rizzo C. ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health. Front Public Health. 2023;11:1166120. doi: 10.3389/fpubh.2023.1166120. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.3389/fpubh.2023.1166120</ArticleId><ArticleId IdType="pmc">PMC10166793</ArticleId><ArticleId IdType="pubmed">37181697</ArticleId></ArticleIdList></Reference><Reference><Citation>Xiao Z, Yuan X, Liao QV, Abdelghani R, Oudeyer PY. Supporting qualitative analysis with large language models: combining codebook with GPT-3 for deductive coding. Proceedings of the 28th International Conference on Intelligent User Interfaces; IUI '23; March 27-31, 2023; Sydney, Australia. 2023. pp. 75–8. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1145/3581754.3584136</ArticleId><ArticleId IdType="doi">10.1145/3581754.3584136</ArticleId></ArticleIdList></Reference><Reference><Citation>Gilardi F, Alizadeh M, Kubli M. ChatGPT outperforms crowd workers for text-annotation tasks. Proc Natl Acad Sci U S A. 2023 Jul 25;120(30):e2305016120. doi: 10.1073/pnas.2305016120. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1073/pnas.2305016120?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub0pubmed</ArticleId><ArticleId IdType="doi">10.1073/pnas.2305016120</ArticleId><ArticleId IdType="pmc">PMC10372638</ArticleId><ArticleId IdType="pubmed">37463210</ArticleId></ArticleIdList></Reference><Reference><Citation>van Nuland M, Erdogan A, Aςar C, Contrucci R, Hilbrants S, Maanach L, Egberts T, van der Linden PD. Performance of ChatGPT on factual knowledge questions regarding clinical pharmacy. J Clin Pharmacol. 2024 Sep 16;64(9):1095–100. doi: 10.1002/jcph.2443.</Citation><ArticleIdList><ArticleId IdType="doi">10.1002/jcph.2443</ArticleId><ArticleId IdType="pubmed">38623909</ArticleId></ArticleIdList></Reference><Reference><Citation>Kareem W, Abbas N. Fighting lies with intelligence: using large language models and chain of thoughts technique to combat fake news. Proceedings of the 43rd SGAI International Conference on Artificial Intelligence; SGAI '23; December 12-14, 2023; Cambridge, UK. 2023. pp. 253–8. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/978-3-031-47994-6_24</ArticleId><ArticleId IdType="doi">10.1007/978-3-031-47994-6_24</ArticleId></ArticleIdList></Reference><Reference><Citation>Haupt MR, Chiu M, Chang J, Li Z, Cuomo R, Mackey TK. Detecting nuance in conspiracy discourse: advancing methods in infodemiology and communication science with machine learning and qualitative content coding. PLoS One. 2023 Dec 20;18(12):e0295414. doi: 10.1371/journal.pone.0295414. 
 
PONE-D-23-14668</Citation><ArticleIdList><ArticleId IdType="doi">10.1371/journal.pone.0295414</ArticleId><ArticleId IdType="doi">10.1371/journal.pone.0295414</ArticleId><ArticleId IdType="pmc">PMC10732406</ArticleId><ArticleId IdType="pubmed">38117843</ArticleId></ArticleIdList></Reference><Reference><Citation>Thirunavukarasu AJ, Ting DS, Elangovan K, Gutierrez L, Tan TF, Ting DS. Large language models in medicine. Nat Med. 2023 Aug 17;29(8):1930–40. doi: 10.1038/s41591-023-02448-8.10.1038/s41591-023-02448-8</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41591-023-02448-8</ArticleId><ArticleId IdType="pubmed">37460753</ArticleId></ArticleIdList></Reference><Reference><Citation>Yin W, Zubiaga A. Hidden behind the obvious: misleading keywords and implicitly abusive language on social media. Online Soc Netw Media. 2022 Jul;30:100210. doi: 10.1016/j.osnem.2022.100210.</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.osnem.2022.100210</ArticleId></ArticleIdList></Reference><Reference><Citation>Ahire LK, Babar SD, Shinde GR. Sarcasm detection in online social network: myths, realities, and issues. In: Mahalle PN, Shinde GR, Dey N, Hassanien AE, editors. Security Issues and Privacy Threats in Smart Ubiquitous Computing. Cham, Switzerland: Springer; 2021. pp. 227–38.</Citation></Reference><Reference><Citation>Ramakristanaiah C, Namratha P, Ganiya RK, Reddy MR. A survey on humor detection methods in communications. Proceedings of the 5th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud); I-SMAC '21; November 11-13, 2021; Palladam, India. 2021. pp. 668–74. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/i-smac52330.2021.9640751</ArticleId></ArticleIdList></Reference><Reference><Citation>Bedi M, Kumar S, Akhtar MS, Chakraborty T. Multi-modal sarcasm detection and humor classification in code-mixed conversations. IEEE Trans Affective Comput. 2023 Apr 1;14(2):1363–75. doi: 10.1109/taffc.2021.3083522.</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/taffc.2021.3083522</ArticleId></ArticleIdList></Reference><Reference><Citation>Wicana SG, İbisoglu TY, Yavanoglu U. A review on sarcasm detection from machine-learning perspective. Proceedings of the 2017 IEEE 11th International Conference on Semantic Computing; ICSC '17; January 30- February 1, 2017; San Diego, CA. 2017. pp. 469–76. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/icsc.2017.74</ArticleId></ArticleIdList></Reference><Reference><Citation>Bruine de Bruin W, Saw HW, Goldman DP. Political polarization in US residents' COVID-19 risk perceptions, policy preferences, and protective behaviors. J Risk Uncertain. 2020 Nov 18;61(2):177–94. doi: 10.1007/s11166-020-09336-3. 
 
9336</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/s11166-020-09336-3</ArticleId><ArticleId IdType="pmc">PMC7672261</ArticleId><ArticleId IdType="pubmed">33223612</ArticleId></ArticleIdList></Reference><Reference><Citation>Kerr J, Panagopoulos C, van der Linden S. Political polarization on COVID-19 pandemic response in the United States. Pers Individ Dif. 2021 Sep;179:110892. doi: 10.1016/j.paid.2021.110892. 
 
S0191-8869(21)00267-1</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.paid.2021.110892</ArticleId><ArticleId IdType="pmc">PMC8631569</ArticleId><ArticleId IdType="pubmed">34866723</ArticleId></ArticleIdList></Reference><Reference><Citation>Levin JM, Bukowski LA, Minson JA, Kahn JM. The political polarization of COVID-19 treatments among physicians and laypeople in the United States. Proc Natl Acad Sci U S A. 2023 Feb 14;120(7):e2216179120. doi: 10.1073/pnas.2216179120. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1073/pnas.2216179120?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub0pubmed</ArticleId><ArticleId IdType="doi">10.1073/pnas.2216179120</ArticleId><ArticleId IdType="pmc">PMC9963903</ArticleId><ArticleId IdType="pubmed">36753464</ArticleId></ArticleIdList></Reference><Reference><Citation>Tsamakis K, Tsiptsios D, Stubbs B, Ma R, Romano E, Mueller C, Ahmad A, Triantafyllis AS, Tsitsas G, Dragioti E. Summarising data and factors associated with COVID-19 related conspiracy theories in the first year of the pandemic: a systematic review and narrative synthesis. BMC Psychol. 2022 Nov 01;10(1):244. doi: 10.1186/s40359-022-00959-6. 
 
10.1186/s40359-022-00959-6</Citation><ArticleIdList><ArticleId IdType="doi">10.1186/s40359-022-00959-6</ArticleId><ArticleId IdType="doi">10.1186/s40359-022-00959-6</ArticleId><ArticleId IdType="pmc">PMC9623972</ArticleId><ArticleId IdType="pubmed">36320071</ArticleId></ArticleIdList></Reference><Reference><Citation>Kaufman RA, Haupt MR, Dow SP. Who's in the crowd matters: cognitive factors and beliefs predict misinformation assessment accuracy. Proc ACM Hum Comput Interact. 2022 Nov 11;6(CSCW2):1–18. doi: 10.1145/3555611.</Citation><ArticleIdList><ArticleId IdType="doi">10.1145/3555611</ArticleId><ArticleId IdType="pubmed">0</ArticleId></ArticleIdList></Reference><Reference><Citation>Delmastro M, Paciello M. Depression, reduced education, and bias perceptions as risk factors of beliefs in misinformation. Sci Rep. 2022 Sep 30;12(1):16408. doi: 10.1038/s41598-022-20640-7. doi: 10.1038/s41598-022-20640-7.10.1038/s41598-022-20640-7</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41598-022-20640-7</ArticleId><ArticleId IdType="doi">10.1038/s41598-022-20640-7</ArticleId><ArticleId IdType="pmc">PMC9524309</ArticleId><ArticleId IdType="pubmed">36180772</ArticleId></ArticleIdList></Reference><Reference><Citation>van der Linden S. Misinformation: susceptibility, spread, and interventions to immunize the public. Nat Med. 2022 Mar 10;28(3):460–7. doi: 10.1038/s41591-022-01713-6.10.1038/s41591-022-01713-6</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41591-022-01713-6</ArticleId><ArticleId IdType="pubmed">35273402</ArticleId></ArticleIdList></Reference><Reference><Citation>Piksa M, Noworyta K, Piasecki J, Gwiazdzinski P, Gundersen AB, Kunst J, Rygula R. Cognitive processes and personality traits underlying four phenotypes of susceptibility to (mis)information. Front Psychiatry. 2022 Jun 15;13:912397. doi: 10.3389/fpsyt.2022.912397. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.3389/fpsyt.2022.912397</ArticleId><ArticleId IdType="pmc">PMC9240766</ArticleId><ArticleId IdType="pubmed">35782415</ArticleId></ArticleIdList></Reference><Reference><Citation>Kahan DM. The politically motivated reasoning paradigm. SSRN Journal. Preprint posted online December 13, 2015.  doi: 10.1002/9781118900772.etrds0417. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1002/9781118900772.etrds0417</ArticleId></ArticleIdList></Reference><Reference><Citation>Kahan DM, Peters E, Wittlin M, Slovic P, Ouellette LL, Braman D, Mandel G. The polarizing impact of science literacy and numeracy on perceived climate change risks. Nature Clim Change. 2012 May 27;2(10):732–5. doi: 10.1038/nclimate1547.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/nclimate1547</ArticleId></ArticleIdList></Reference><Reference><Citation>Kahan DM, Peters E, Dawson EC, Slovic P. Motivated numeracy and enlightened self-government. Behav Public Policy. 2017 May 31;1(1):54–86. doi: 10.1017/bpp.2016.2.</Citation><ArticleIdList><ArticleId IdType="doi">10.1017/bpp.2016.2</ArticleId></ArticleIdList></Reference><Reference><Citation>Hughes S, Machan L. It's a conspiracy: COVID-19 conspiracies link to psychopathy, machiavellianism and collective narcissism. Pers Individ Dif. 2021 Mar;171:110559. doi: 10.1016/j.paid.2020.110559. 
 
S0191-8869(20)30750-9</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.paid.2020.110559</ArticleId><ArticleId IdType="pmc">PMC8035125</ArticleId><ArticleId IdType="pubmed">33867616</ArticleId></ArticleIdList></Reference><Reference><Citation>Sternisko A, Cichocka A, Cislak A, Van Bavel JJ. National narcissism predicts the belief in and the dissemination of conspiracy theories during the COVID-19 pandemic: evidence from 56 countries. Pers Soc Psychol Bull. 2023 Jan;49(1):48–65. doi: 10.1177/01461672211054947. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1177/01461672211054947</ArticleId><ArticleId IdType="pmc">PMC9684064</ArticleId><ArticleId IdType="pubmed">34872399</ArticleId></ArticleIdList></Reference><Reference><Citation>Chen B, Zhang Z, Langrené N, Zhu S. Unleashing the potential of prompt engineering in large language models: a comprehensive review. arXiv. Preprint posted online October 23, 2023.  
 
</Citation></Reference><Reference><Citation>Xu B, Yang A, Lin J, Wang Q, Zhou C, Zhang Y, Mao Z. ExpertPrompting: instructing large language models to be distinguished experts. arXiv. Preprint posted online May 24, 2023.  doi: 10.48550/arXiv.2305.14688. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.48550/arXiv.2305.14688</ArticleId></ArticleIdList></Reference><Reference><Citation>Wang Z, Peng Z, Que H, Liu J, Zhou W, Wu Y, Guo H, Gan R, Ni Z, Yang J, Zhang M, Zhang Z, Ouyang W, Xu K, Huang SW, Fuentes J, Peng J. RoleLLM: benchmarking, eliciting, and enhancing role-playing abilities of large language models. arXiv. Preprint posted online October 1, 2023.  
 
</Citation></Reference><Reference><Citation>Geleris J, Sun Y, Platt J, Zucker J, Baldwin M, Hripcsak G, Labella A, Manson DK, Kubin C, Barr RG, Sobieszczyk ME, Schluger NW. Observational study of hydroxychloroquine in hospitalized patients with COVID-19. N Engl J Med. 2020 Jun 18;382(25):2411–8. doi: 10.1056/nejmoa2012410.</Citation><ArticleIdList><ArticleId IdType="doi">10.1056/nejmoa2012410</ArticleId><ArticleId IdType="pmc">PMC7224609</ArticleId><ArticleId IdType="pubmed">32379955</ArticleId></ArticleIdList></Reference><Reference><Citation>Haupt MR, Li J, Mackey TK. Identifying and characterizing scientific authority-related misinformation discourse about hydroxychloroquine on twitter using unsupervised machine learning. Big Data Soc. 2021 May 06;8(1):205395172110138. doi: 10.1177/20539517211013843.</Citation><ArticleIdList><ArticleId IdType="doi">10.1177/20539517211013843</ArticleId></ArticleIdList></Reference><Reference><Citation>Mackey TK, Purushothaman V, Haupt M, Nali MC, Li J. Application of unsupervised machine learning to identify and characterise hydroxychloroquine misinformation on Twitter. Lancet Digit Health. 2021 Feb;3(2):e72–5. doi: 10.1016/S2589-7500(20)30318-6. 
 
S2589-7500(20)30318-6</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/S2589-7500(20)30318-6</ArticleId><ArticleId IdType="pubmed">33509386</ArticleId></ArticleIdList></Reference><Reference><Citation>Tandoc EC, Lim ZW, Ling R. Defining “fake news”. Digit Journal. 2017 Aug 30;6(2):137–53. doi: 10.1080/21670811.2017.1360143.</Citation><ArticleIdList><ArticleId IdType="doi">10.1080/21670811.2017.1360143</ArticleId></ArticleIdList></Reference><Reference><Citation>Waszak PM, Kasprzycka-Waszak W, Kubanek A. The spread of medical fake news in social media – the pilot quantitative study. Health Policy Technol. 2018 Jun;7(2):115–8. doi: 10.1016/j.hlpt.2018.03.002.</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.hlpt.2018.03.002</ArticleId></ArticleIdList></Reference><Reference><Citation>COVID-19 vaccine facts. Centers for Disease Control and Prevention.  [2024-05-03].  
 https://www.cdc.gov/coronavirus/2019-ncov/vaccines/facts.html
.</Citation></Reference><Reference><Citation>Debunking myths about COVID-19. Mayo Clinic.  [2024-05-03].  
 https://www.mayoclinichealthsystem.org/hometown-health/featured-topic/covid-19-vaccine-myths-debunked
.</Citation></Reference><Reference><Citation>Sahoo S, Padhy SK, Ipsita J, Mehra A, Grover S. Demystifying the myths about COVID-19 infection and its societal importance. Asian J Psychiatr. 2020 Dec;54:102244. doi: 10.1016/j.ajp.2020.102244. 
 
S1876-2018(20)30356-7</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.ajp.2020.102244</ArticleId><ArticleId IdType="pmc">PMC7301136</ArticleId><ArticleId IdType="pubmed">32593121</ArticleId></ArticleIdList></Reference><Reference><Citation>Vraga EK, Bode L. Correction as a solution for health misinformation on social media. Am J Public Health. 2020 Oct;110(S3):S278–80. doi: 10.2105/ajph.2020.305916.</Citation><ArticleIdList><ArticleId IdType="doi">10.2105/ajph.2020.305916</ArticleId><ArticleId IdType="pmc">PMC7532323</ArticleId><ArticleId IdType="pubmed">33001724</ArticleId></ArticleIdList></Reference><Reference><Citation>Poirier L. Reading datasets: strategies for interpreting the politics of data signification. Big Data Soc. 2021 Jul 01;8(2):205395172110293. doi: 10.1177/20539517211029322.</Citation><ArticleIdList><ArticleId IdType="doi">10.1177/20539517211029322</ArticleId></ArticleIdList></Reference><Reference><Citation>Schwartz IS, Link KE, Daneshjou R, Cortés-Penfield N. Black box warning: large language models and the future of infectious diseases consultation. Clin Infect Dis. 2024 Apr 10;78(4):860–6. doi: 10.1093/cid/ciad633. 
 
7424520</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/cid/ciad633</ArticleId><ArticleId IdType="pmc">PMC11006107</ArticleId><ArticleId IdType="pubmed">37971399</ArticleId></ArticleIdList></Reference><Reference><Citation>Amann J, Blasimme A, Vayena E, Frey D, Madai VI, Precise4Q consortium  Explainability for artificial intelligence in healthcare: a multidisciplinary perspective. BMC Med Inform Decis Mak. 2020 Nov 30;20(1):310. doi: 10.1186/s12911-020-01332-6. 
 
10.1186/s12911-020-01332-6</Citation><ArticleIdList><ArticleId IdType="doi">10.1186/s12911-020-01332-6</ArticleId><ArticleId IdType="doi">10.1186/s12911-020-01332-6</ArticleId><ArticleId IdType="pmc">PMC7706019</ArticleId><ArticleId IdType="pubmed">33256715</ArticleId></ArticleIdList></Reference><Reference><Citation>González-Ibáñez R, Muresan S, Wacholder N. Identifying sarcasm in Twitter: a closer look. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies; HLT '11; June 19-24, 2011; Portland, OR. 2011. pp. 581–6. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.5555/2002736</ArticleId></ArticleIdList></Reference><Reference><Citation>Haupt MR, Weiss SM, Chiu M, Cuomo R, Chein JM, Mackey T. Psychological and situational profiles of social distance compliance during COVID-19. J Commun Healthc. 2022 Feb 01;15(1):44–53. doi: 10.1080/17538068.2022.2026055.</Citation><ArticleIdList><ArticleId IdType="doi">10.1080/17538068.2022.2026055</ArticleId></ArticleIdList></Reference><Reference><Citation>Alsaadi B, Alahmadi D. The use of persona towards human-centered design in health field: review of types and technologies. Proceedings of the 2021 International Conference on e-Health and Bioengineering; EHB '21; November 18-19, 2021; Iasi, Romania. 2021. pp. 1–4. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/ehb52898.2021.9657744</ArticleId></ArticleIdList></Reference><Reference><Citation>Huh J, Kwon BC, Kim SH, Lee S, Choo J, Kim J, Choi M, Yi JS. Personas in online health communities. J Biomed Inform. 2016 Oct;63:212–25. doi: 10.1016/j.jbi.2016.08.019. 
 
S1532-0464(16)30101-0</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.jbi.2016.08.019</ArticleId><ArticleId IdType="pmc">PMC5268468</ArticleId><ArticleId IdType="pubmed">27568913</ArticleId></ArticleIdList></Reference><Reference><Citation>Massey PM, Chiang SC, Rose M, Murray RM, Rockett M, Togo E, Klassen AC, Manganello JA, Leader AE. Development of personas to communicate narrative-based information about the HPV vaccine on Twitter. Front Digit Health. 2021 Aug 4;3:682639. doi: 10.3389/fdgth.2021.682639. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.3389/fdgth.2021.682639</ArticleId><ArticleId IdType="pmc">PMC8521793</ArticleId><ArticleId IdType="pubmed">34713151</ArticleId></ArticleIdList></Reference><Reference><Citation>Mei Q, Xie Y, Yuan W, Jackson MO. A turing test of whether AI chatbots are behaviorally similar to humans. Proc Natl Acad Sci U S A. 2024 Feb 27;121(9):e2313925121. doi: 10.1073/pnas.2313925121. 
 
</Citation><ArticleIdList><ArticleId IdType="doi">10.1073/pnas.2313925121?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub0pubmed</ArticleId><ArticleId IdType="doi">10.1073/pnas.2313925121</ArticleId><ArticleId IdType="pmc">PMC10907317</ArticleId><ArticleId IdType="pubmed">38386710</ArticleId></ArticleIdList></Reference><Reference><Citation>Park PS, Goldstein S, O'Gara A, Chen M, Hendrycks D. AI deception: a survey of examples, risks, and potential solutions. Patterns (N Y) 2024 May 10;5(5):100988. doi: 10.1016/j.patter.2024.100988. 
 
S2666-3899(24)00103-X</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.patter.2024.100988</ArticleId><ArticleId IdType="pmc">PMC11117051</ArticleId><ArticleId IdType="pubmed">38800366</ArticleId></ArticleIdList></Reference><Reference><Citation>Hajli N, Saeed U, Tajvidi M, Shirazi F. Social bots and the spread of disinformation in social media: the challenges of artificial intelligence. Br J Manag. 2021 Oct 30;33(3):1238–53. doi: 10.1111/1467-8551.12554.</Citation><ArticleIdList><ArticleId IdType="doi">10.1111/1467-8551.12554</ArticleId></ArticleIdList></Reference><Reference><Citation>Arnold V, Purnat TD, Marten R, Pattison A, Gouda H. Chatbots and COVID-19: taking stock of the lessons learned. J Med Internet Res. 2024 Mar 21;26:e54840. doi: 10.2196/54840. 
 
v26i1e54840</Citation><ArticleIdList><ArticleId IdType="doi">10.2196/54840</ArticleId><ArticleId IdType="pmc">PMC10959167</ArticleId><ArticleId IdType="pubmed">38512309</ArticleId></ArticleIdList></Reference><Reference><Citation>Leavitt A, Robinson JJ. Upvote my news: the practices of peer information aggregation for breaking news on reddit.com. Proc ACM Hum Comput Interact. 2017 Dec 06;1(CSCW):1–18. doi: 10.1145/3134700.</Citation><ArticleIdList><ArticleId IdType="doi">10.1145/3134700</ArticleId></ArticleIdList></Reference><Reference><Citation>DeVito MA. From editors to algorithms: a values-based approach to understanding story selection in the Facebook news feed. Digit Journal. 2016 May 12;5(6):753–73. doi: 10.1080/21670811.2016.1178592.</Citation><ArticleIdList><ArticleId IdType="doi">10.1080/21670811.2016.1178592</ArticleId></ArticleIdList></Reference><Reference><Citation>flashssd / ChatGPT-misinfo-detection. GitHub.  [2024-04-29].  
 https://github.com/flashssd/ChatGPT-Misinfo-Detection/
</Citation></Reference></ReferenceList></PubmedData></PubmedArticle>