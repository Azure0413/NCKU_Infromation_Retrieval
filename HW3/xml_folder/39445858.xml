<PubmedArticle><MedlineCitation Status="Publisher" Owner="NLM"><PMID Version="1">39445858</PMID><DateRevised><Year>2024</Year><Month>10</Month><Day>24</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1365-2753</ISSN><JournalIssue CitedMedium="Internet"><PubDate><Year>2024</Year><Month>Oct</Month><Day>24</Day></PubDate></JournalIssue><Title>Journal of evaluation in clinical practice</Title><ISOAbbreviation>J Eval Clin Pract</ISOAbbreviation></Journal><ArticleTitle>The equivalence of a high-stakes objective structured clinical exam adapted to suit a virtual delivery format.</ArticleTitle><ELocationID EIdType="doi" ValidYN="Y">10.1111/jep.14167</ELocationID><Abstract><AbstractText Label="INTRODUCTION" NlmCategory="BACKGROUND">The COVID-19 pandemic necessitated rapid adaptation of clinical competence assessments, including the transition of Objective Structured Clinical Examinations (OSCE) from in-person to virtual formats. This study investigates the construct equivalence of a high-stakes OSCE, originally designed for in-person delivery, when adapted for a virtual format.</AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">A retrospective analysis was conducted using OSCE scores from the Internationally Educated Nurse Competency Assessment Program (IENCAP®). Data were collected from 15 exam administrations between January 2018 and June 2022, encompassing 2021 examinees (1936 in-person, 85 virtual). The Many-Facet Rasch Measurement (MFRM) model was employed to analyze the invariance of examinee ability, case difficulty, and criteria difficulty across in-person and virtual formats.</AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">Results revealed overall examinee ability estimates remained invariant regardless of the OSCE format, while invariant violations were identified in only three of the 15 cases (N = 20%) adapted to suit the virtual format. The most significant adaptation, namely the use of a verbal physical examination to suit the virtual context achieved equivalence to its hands-on in-person counterpart given evidence of invariance across criteria estimates. Interestingly, criteria scores in invariant violated cases displayed a higher level of stability or consistency across the virtual OSCE formats versus their in-person counterpart highlighting a potential benefit of the virtual versus in-person format and potentially linked to the verbal physical examination.</AbstractText><AbstractText Label="CONCLUSION" NlmCategory="CONCLUSIONS">The study found that while examinee ability and case difficulty estimates exhibited some invariance between in-person and virtual OSCE formats, criteria involving physical assessments faced challenges in maintaining construct equivalence. These findings highlight the need for careful consideration in adapting high-stakes clinical assessments to virtual formats to ensure fairness and reliability.</AbstractText><CopyrightInformation>© 2024 The Author(s). Journal of Evaluation in Clinical Practice published by John Wiley &amp; Sons Ltd.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Amarthalingam</LastName><ForeName>Luxshi</ForeName><Initials>L</Initials><Identifier Source="ORCID">0000-0003-1097-1997</Identifier><AffiliationInfo><Affiliation>Touchstone Institute, Toronto, Ontario, Canada.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Monteiro</LastName><ForeName>Sandra</ForeName><Initials>S</Initials><Identifier Source="ORCID">0000-0001-8723-5942</Identifier><AffiliationInfo><Affiliation>Division of Education and Innovation, Department of Medicine, McMaster University, Hamilton, Ontario, Canada.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Coetzee</LastName><ForeName>Karen</ForeName><Initials>K</Initials><AffiliationInfo><Affiliation>Construct Measures, Rancho, Ontario, Canada.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Eftekari</LastName><ForeName>Tabasom</ForeName><Initials>T</Initials><AffiliationInfo><Affiliation>Touchstone Institute, Toronto, Ontario, Canada.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2024</Year><Month>10</Month><Day>24</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>J Eval Clin Pract</MedlineTA><NlmUniqueID>9609066</NlmUniqueID><ISSNLinking>1356-1294</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">construct equivalence</Keyword><Keyword MajorTopicYN="N">invariance violation</Keyword><Keyword MajorTopicYN="N">many‐facets rasch measurement</Keyword><Keyword MajorTopicYN="N">verbal physical examination</Keyword><Keyword MajorTopicYN="N">virtual OSCE</Keyword><Keyword MajorTopicYN="N">virtual assessment</Keyword></KeywordList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="revised"><Year>2024</Year><Month>7</Month><Day>31</Day></PubMedPubDate><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>1</Month><Day>9</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>9</Month><Day>25</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>10</Month><Day>24</Day><Hour>16</Hour><Minute>21</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>10</Month><Day>24</Day><Hour>16</Hour><Minute>21</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>10</Month><Day>24</Day><Hour>9</Hour><Minute>14</Minute></PubMedPubDate></History><PublicationStatus>aheadofprint</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39445858</ArticleId><ArticleId IdType="doi">10.1111/jep.14167</ArticleId></ArticleIdList><ReferenceList><Title>REFERENCES</Title><Reference><Citation>Blythe J, Patel NSA, Spiring W, et al. Undertaking a high stakes virtual OSCE (“VOSCE”) during Covid‐19. BMC Med Educ. 2021;21(1):221.</Citation></Reference><Reference><Citation>Choi A, Morrison LJ, Murtha T, Talwalkar J. A comparison between In‐Person and virtual OSCE on advanced communication skills for senior medical students (Sci200). J Pain Symptom Manage. 2023;65(5):e639‐e640.</Citation></Reference><Reference><Citation>Grover S, Pandya M, Ranasinghe C, Ramji SP, Bola H, Raj S. Assessing the utility of virtual OSCE sessions as an educational tool: a national pilot study. BMC Med Educ. 2022;22(1):178.</Citation></Reference><Reference><Citation>Coyne E, Calleja P, Forster E, Lin F. A review of virtual‐simulation for assessing healthcare students' clinical competency. Nurse Educ Today. 2021;96:104623.</Citation></Reference><Reference><Citation>Smee S. ABC of learning and teaching in Medicine ‘skill based assessment. BMJ. 2003;326:703‐706.</Citation></Reference><Reference><Citation>Stewart G, Strachan A. Sustaining an occupation‐specific language assessment for the Canadian healthcare field. TESL Canada J. 2021;38(1):49‐66.</Citation></Reference><Reference><Citation>Round J, Conradi E, Poulton T. Improving assessment with virtual patients. Med Teach. 2009;31(8):759‐763.</Citation></Reference><Reference><Citation>Clark AK, Karvonen M. Constructing and evaluating a validation argument for a next‐generation alternate assessment. Educational Assessment. 2020;25(1):47‐64.</Citation></Reference><Reference><Citation>American Educational Research Association, American Psychological Association, &amp; National Council on Measurement in Education. (Eds.) Standards for educational and psychological testing. American Educational Research Association; 2014.</Citation></Reference><Reference><Citation>Iramaneerat C, Yudkowsky R. Rater errors in a clinical skills assessment of medical students. Eval Health Prof. 2007;30(3):266‐283.</Citation></Reference><Reference><Citation>Monteiro S, McConnell MM. Evaluating the construct validity of competencies: a retrospective analysis. Med Sci Educ. 2023;33(729):736.</Citation></Reference><Reference><Citation>Wang P, Coetzee K, Strachan A, Monteiro S, Cheng L. Examining rater performance on the CELBAN speaking: a many‐facets rasch measurement analysis. Can J Appl Linguist. 2020;23(2):73‐95.</Citation></Reference><Reference><Citation>Yeates P, Moult A, Cope N, et al. Measuring the effect of examiner variability in a multiple‐circuit objective structured clinical examination (OSCE). Acad Med. 2021;96(8):1189‐1196.</Citation></Reference><Reference><Citation>Wass V, Van der Vleuten C, Shatzer J, Jones R. Assessment of clinical competence. The Lancet. 2001;357(9260):945‐949.</Citation></Reference><Reference><Citation>Khalaf K, El‐Kishawi M, Moufti MA, Al Kawas S. Introducing a comprehensive high‐stake online exam to final‐year dental students during the COVID‐19 pandemic and evaluation of its effectiveness. Med Educ Online. 2020;25(1):1826861.</Citation></Reference><Reference><Citation>Bartman I, Smee S, Roy M. A method for identifying extreme OSCE examiners. The Clinical Teacher. 2013;10(1):27‐31.</Citation></Reference><Reference><Citation>Coetzee K, Monteiro S. Drift happens, sometimes: examining time based rater variance in a high‐stakes OSCE. Med Teach. 2019;41(7):819‐823.</Citation></Reference><Reference><Citation>Harasym PH, Woloschuk W, Cunning L. Undesired variance due to examiner stringency/leniency effect in communication skill scores assessed in OSCEs. Adv Health Sci Educ. 2008;13(5):617‐632.</Citation></Reference><Reference><Citation>Harden RM, Lilley P, Patricio M. The Definitive Guide to the OSCE: The Objective Structured Clinical Examination as a performance assessment. Elsevier Health Sciences; 2015.</Citation></Reference><Reference><Citation>Iramaneerat C, Yudkowsky R, Myford CM, Downing SM. Quality control of an OSCE using generalizability theory and many‐faceted rasch measurement. Adv Health Sci Educ. 2008;13(4):479‐493.</Citation></Reference><Reference><Citation>Tavares W, Eva KW. Impact of rating demands on rater‐based assessments of clinical competence. Educ Primary Care. 2014;25(6):308‐318.</Citation></Reference><Reference><Citation>Baig LA, Violato C. Temporal stability of objective structured clinical exams: a longitudinal study employing item response theory. BMC Med Educ. 2012;12(121):121.</Citation></Reference><Reference><Citation>Khan KZ, Ramachandran S, Gaunt K, Pushkar P. The objective structured clinical examination (OSCE): AMEE guide no. 81. part I: an historical and theoretical perspective. Med Teach. 2013;35(9):e1437‐e1446.</Citation></Reference><Reference><Citation>Reznick RK, Blackmore D, Dauphinee WD, Rothman AI, Smee S. Large‐scale high‐stakes testing with an OSCE: report from the medical council of Canada. Acad Med. 1996;71(1 suppl):S19‐S21.</Citation></Reference><Reference><Citation>Reznick R, Smee S, Rothman A, et al. An objective structured clinical examination for the licentiate; report of the pilot project of the medical council of Canada. Acad Med. 1992;67(8):487‐494.</Citation></Reference><Reference><Citation>Tan CK, Chua WL, Vu CK, Chang JP. High‐stakes examinations during the COVID‐19 pandemic: to proceed or not to proceed, that is the question. Postgraduate Medical Journal. 2021;97(1149):427‐31.</Citation></Reference><Reference><Citation>Eckes T (2009). Many‐facet Rasch measurement. Common European Framework of Reference for Languages: Learning, teaching, assessment (Section H). Retrieved from https://www.gast.de/fileadmin/gast.de/GAST/4_PDF/2-Forschung-Entwicklung/Publikationen/MFRM-CoE.pdf</Citation></Reference><Reference><Citation>Myford CM, Wolfe EW. Detecting and measuring rater effects using many‐facet rasch measurement: part I. J Appl Meas. 2003;4(4):386‐422.</Citation></Reference><Reference><Citation>Linacre JM (2020). DIF‐DPF‐bias‐interactions concepts, Retrieved from www.winsteps.com/facetman/webpage.htm</Citation></Reference><Reference><Citation>Andrich D. A rating formulation for ordered response categories. Psychometrika. 1978;43:561‐573.</Citation></Reference><Reference><Citation>Linacre JM Facets computer program for many‐facet Rasch measurement, version 3.83.1. Winsteps.com; 2020.</Citation></Reference><Reference><Citation>Linacre JM (2012). Many‐facets measurement: Facets Tutorial. Retrieved from https://www.winsteps.com/a/ftutorial4.pdf</Citation></Reference><Reference><Citation>Bond TG, Fox CM. Applying the Rasch model: Fundamental measurement in the human sciences. (3rd ed.). Routledge; 2015.</Citation></Reference><Reference><Citation>Meyers LS, Gamst G, Guarino AJ Applied multivariate research: Design and interpretation. 2nd ed. Sage Publications; 2013.</Citation></Reference><Reference><Citation>Eckes T. (2009). Many‐facet Rasch measurement. Common European Framework of Reference for Languages: Learning, teaching, assessment (Section H). Retrieved from https://www.gast.de/fileadmin/gast.de/GAST/4_PDF/2-Forschung-Entwicklung/Publikationen/MFRM-CoE.pdf</Citation></Reference><Reference><Citation>Myford CM, Wolfe EW. Detecting and measuring rater effects using many‐facet rasch measurement: part I. J Appl Meas. 2003;4(4):386‐422.</Citation></Reference><Reference><Citation>Linacre JM. (2020). DIF‐DPF‐bias‐interactions concepts, Retrieved from www.winsteps.com/facetman/webpage.htm</Citation></Reference><Reference><Citation>Andrich D. A rating formulation for ordered response categories. Psychometrika. 1978;43:561‐573.</Citation></Reference><Reference><Citation>Linacre JM. Facets computer program for many‐facet Rasch measurement, version 3.83.1. Winsteps.com; 2020.</Citation></Reference><Reference><Citation>Linacre JM. (2012). Many‐facets measurement: Facets Tutorial. Retrieved from https://www.winsteps.com/a/ftutorial4.pdf</Citation></Reference><Reference><Citation>Khan FA, Williams M, Napolitano CA. Resident education during Covid‐19, virtual mock OSCE's via zoom: a pilot program. J Clin Anesth. 2021;69:110107.</Citation></Reference><Reference><Citation>Donn J, Scott JA, Binnie V, Bell A. A pilot of a virtual objective structured clinical examination in dental education. A response to COVID‐19. Eur J Dental Ed. 2021;25(3):488‐494.</Citation></Reference><Reference><Citation>Lee H, Geisinger KF. Item parameter drift in context questionnaires from international large‐scale assessments. Int J Test. 2019;19(1):23‐51.</Citation></Reference><Reference><Citation>Hopwood J, Myers G, Sturrock A. Twelve tips for conducting a virtual OSCE. Med Teach. 2021;43(6):633‐636.</Citation></Reference><Reference><Citation>Bearman M, Ajjawi R, Bennett S, Boud D. The hidden labours of designing the objective structured clinical examination: a practice theory study. Adv Health Sci Educ. 2021;26(2):637‐651.</Citation></Reference><Reference><Citation>Chan SCC, Choa G, Kelly J, Maru D, Rashid MA. Implementation of virtual OSCE in health professions education: a systematic review. Med Educ. 2023;57(9):833‐843.</Citation></Reference></ReferenceList></PubmedData></PubmedArticle>