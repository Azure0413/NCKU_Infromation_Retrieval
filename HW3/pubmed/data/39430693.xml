<PubmedArticle><MedlineCitation Status="PubMed-not-MEDLINE" Owner="NLM"><PMID Version="1">39430693</PMID><DateRevised><Year>2024</Year><Month>10</Month><Day>23</Day></DateRevised><Article PubModel="Electronic-eCollection"><Journal><ISSN IssnType="Print">2055-2076</ISSN><JournalIssue CitedMedium="Print"><Volume>10</Volume><PubDate><Year>2024</Year><Season>Jan-Dec</Season></PubDate></JournalIssue><Title>Digital health</Title><ISOAbbreviation>Digit Health</ISOAbbreviation></Journal><ArticleTitle>Assessing AI efficacy in medical knowledge tests: A study using Taiwan's internal medicine exam questions from 2020 to 2023.</ArticleTitle><Pagination><StartPage>20552076241291404</StartPage><MedlinePgn>20552076241291404</MedlinePgn></Pagination><ELocationID EIdType="pii" ValidYN="Y">20552076241291404</ELocationID><ELocationID EIdType="doi" ValidYN="Y">10.1177/20552076241291404</ELocationID><Abstract><AbstractText Label="BACKGROUND" NlmCategory="UNASSIGNED">The aim of this study is to evaluate the ability of generative artificial intelligence (AI) models to handle specialized medical knowledge and problem-solving in a formal examination context.</AbstractText><AbstractText Label="METHODS" NlmCategory="UNASSIGNED">This research utilized internal medicine exam questions provided by the Taiwan Internal Medicine Society from 2020 to 2023, testing three AI models: GPT-4o, Claude_3.5 Sonnet, and Gemini Advanced models. Rejected queries for Gemini Advanced were translated into French for resubmission. Performance was assessed using IBM SPSS Statistics 26, with accuracy percentages calculated and statistical analyses such as Pearson correlation and analysis of variance (ANOVA) performed to gauge AI efficacy.</AbstractText><AbstractText Label="RESULTS" NlmCategory="UNASSIGNED">GPT-4o's top annual score was 86.25 in 2022, with an average of 81.97. Claude_3.5 Sonnet reached a peak score of 88.13 in 2021 and 2022, averaging 84.85, while Gemini Advanced lagged with an average score of 69.84. In specific specialties, Claude_3.5 Sonnet scored highest in Psychiatry (100%) and Nephrology (97.26%), with GPT-4o performing similarly well in Hematology &amp; oncology (97.10%) and Nephrology (94.52%). Gemini's best scores were in Psychiatry (86.96%) and Hematology &amp; Oncology (82.76%). Gemini Advanced models struggled with Neurology, scoring below 60%. Additionally, all models performed better on text-based questions than on image-based ones, without significant differences. Claude 3 Opus scored highest on COVID-19-related questions at 89.29%, followed by GPT-4o at 75.00% and Gemini Advanced at 67.86%.</AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="UNASSIGNED">AI models showed varied proficiency across medical specialties and question types. GPT-4o demonstrated higher image-based correction rates. Claude_3.5 Sonnet generally and consistently outperformed others, highlighting significant potential for AI in assisting medical education.</AbstractText><CopyrightInformation>© The Author(s) 2024.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Lin</LastName><ForeName>Shih-Yi</ForeName><Initials>SY</Initials><AffiliationInfo><Affiliation>Graduate Institute of Biomedical Sciences, College of Medicine, China Medical University, Taichung.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Division of Nephrology and Kidney Institute, China Medical University Hospital, Taichung.</Affiliation><Identifier Source="RINGGOLD">38020</Identifier></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Hsu</LastName><ForeName>Ying-Yu</ForeName><Initials>YY</Initials><Identifier Source="ORCID">0009-0006-9025-8102</Identifier><AffiliationInfo><Affiliation>11th Grade Student, National Changhua Senior High School, Changhua.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Ju</LastName><ForeName>Shu-Woei</ForeName><Initials>SW</Initials><AffiliationInfo><Affiliation>Division of Nephrology and Kidney Institute, China Medical University Hospital, Taichung.</Affiliation><Identifier Source="RINGGOLD">38020</Identifier></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Yeh</LastName><ForeName>Pei-Chun</ForeName><Initials>PC</Initials><AffiliationInfo><Affiliation>Artificial Intelligence Center, China Medical University Hospital, Taichung.</Affiliation><Identifier Source="RINGGOLD">38020</Identifier></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Hsu</LastName><ForeName>Wu-Huei</ForeName><Initials>WH</Initials><AffiliationInfo><Affiliation>Graduate Institute of Biomedical Sciences, College of Medicine, China Medical University, Taichung.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Chest Medicine, China Medical University Hospital, Taichung.</Affiliation><Identifier Source="RINGGOLD">38020</Identifier></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Kao</LastName><ForeName>Chia-Hung</ForeName><Initials>CH</Initials><Identifier Source="ORCID">0000-0002-6368-3676</Identifier><AffiliationInfo><Affiliation>Graduate Institute of Biomedical Sciences, College of Medicine, China Medical University, Taichung.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Artificial Intelligence Center, China Medical University Hospital, Taichung.</Affiliation><Identifier Source="RINGGOLD">38020</Identifier></AffiliationInfo><AffiliationInfo><Affiliation>Department of Nuclear Medicine and PET Center, China Medical University Hospital, Taichung.</Affiliation><Identifier Source="RINGGOLD">38020</Identifier></AffiliationInfo><AffiliationInfo><Affiliation>Department of Bioinformatics and Medical Engineering, Asia University, Taichung.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2024</Year><Month>10</Month><Day>18</Day></ArticleDate></Article><MedlineJournalInfo><Country>United States</Country><MedlineTA>Digit Health</MedlineTA><NlmUniqueID>101690863</NlmUniqueID><ISSNLinking>2055-2076</ISSNLinking></MedlineJournalInfo><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">ChatGPT-4</Keyword><Keyword MajorTopicYN="N">Claude 3 Opus</Keyword><Keyword MajorTopicYN="N">Gemini</Keyword><Keyword MajorTopicYN="N">Generative AI models</Keyword><Keyword MajorTopicYN="N">internal medicine exam</Keyword></KeywordList><CoiStatement>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>5</Month><Day>22</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>9</Month><Day>27</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>10</Month><Day>21</Day><Hour>10</Hour><Minute>52</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>10</Month><Day>21</Day><Hour>10</Hour><Minute>51</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>10</Month><Day>21</Day><Hour>5</Hour><Minute>51</Minute></PubMedPubDate><PubMedPubDate PubStatus="pmc-release"><Year>2024</Year><Month>10</Month><Day>18</Day></PubMedPubDate></History><PublicationStatus>epublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39430693</ArticleId><ArticleId IdType="pmc">PMC11490985</ArticleId><ArticleId IdType="doi">10.1177/20552076241291404</ArticleId><ArticleId IdType="pii">10.1177_20552076241291404</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Stokel-Walker C, Van Noorden R. What ChatGPT and generative AI mean for science. Nature 2023; 614: 214–216.</Citation><ArticleIdList><ArticleId IdType="pubmed">36747115</ArticleId></ArticleIdList></Reference><Reference><Citation>Reddy S. Generative AI in healthcare: an implementation science informed translational path on application, integration and governance. Implement Sci 2024; 19: 27.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10941464</ArticleId><ArticleId IdType="pubmed">38491544</ArticleId></ArticleIdList></Reference><Reference><Citation>Mesko B. The ChatGPT (generative artificial intelligence) revolution has made artificial intelligence approachable for medical professionals. J Med Internet Res 2023; 25: e48392.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10337400</ArticleId><ArticleId IdType="pubmed">37347508</ArticleId></ArticleIdList></Reference><Reference><Citation>Yu P, Xu H, Hu X, et al. Leveraging generative AI and large language models: a comprehensive roadmap for healthcare integration. Healthcare (Basel) 2023; 11: 2776.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10606429</ArticleId><ArticleId IdType="pubmed">37893850</ArticleId></ArticleIdList></Reference><Reference><Citation>Busch F, Hoffmann L, Rueger C, et al. Systematic review of large language models for patient care: current applications and challenges. medRxiv 2024. doi:10.1101/2024.03.04.24303733</Citation><ArticleIdList><ArticleId IdType="doi">10.1101/2024.03.04.24303733</ArticleId></ArticleIdList></Reference><Reference><Citation>Wang H, Wu W, Dou Z, et al. Performance and exploration of ChatGPT in medical examination, records and education in Chinese: pave the way for medical AI. Int J Med Inform 2023; 177: 105173.</Citation><ArticleIdList><ArticleId IdType="pubmed">37549499</ArticleId></ArticleIdList></Reference><Reference><Citation>Sumbal A, Sumbal R, Amir A. Can ChatGPT-3.5 pass a medical exam? A systematic review of ChatGPT's performance in academic testing. J Med Educ Curric Dev 2024; 11: 23821205241238641.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10938614</ArticleId><ArticleId IdType="pubmed">38487300</ArticleId></ArticleIdList></Reference><Reference><Citation>Gilson A, Safranek C, Huang T, et al. How does ChatGPT perform on the medical licensing exams? The implications of large language models for medical education and knowledge assessment. MedRxiv 2022. doi:10.1101/2022.12.23.22283901</Citation><ArticleIdList><ArticleId IdType="doi">10.1101/2022.12.23.22283901</ArticleId></ArticleIdList></Reference><Reference><Citation>Sallam M, Al-Salahat K. Below average ChatGPT performance in medical microbiology exam compared to university students. Front Educ 2023; 8: 1333415.</Citation></Reference><Reference><Citation>Lin S-Y, Chan PK, Hsu W-H, et al. Exploring the proficiency of ChatGPT-4: an evaluation of its performance in the Taiwan advanced medical licensing examination. Digit Health 2024; 10: 20552076241237678.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10916498</ArticleId><ArticleId IdType="pubmed">38449683</ArticleId></ArticleIdList></Reference><Reference><Citation>Jindal JA, Lungren MP, Shah NH. Ensuring useful adoption of generative artificial intelligence in healthcare. J Am Med Inform Assoc 2024; 31(6): 1441–1444.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC11105148</ArticleId><ArticleId IdType="pubmed">38452298</ArticleId></ArticleIdList></Reference><Reference><Citation>Loscalzo J, Fauci AS, Kasper DL, et al. Harrison's principles of internal medicine. 21 ed. New York, NY: McGraw-Hill Education, 2022. Accessed May 08, 2024.</Citation></Reference><Reference><Citation>Palmer RD. COVID 19 vaccines and the misinterpretation of perceived side effects clarity on the safety of vaccines. Biomedicine (Taipei) 2022; 12: 1–4.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC9629406</ArticleId><ArticleId IdType="pubmed">36381188</ArticleId></ArticleIdList></Reference><Reference><Citation>Introducing the next generation of Claude. https://www.anthropic.com/news/claude-3-family.</Citation></Reference><Reference><Citation>Gemini. https://gemini.google.com/.</Citation></Reference><Reference><Citation>Taiwan Society of Internal Medicine. http://www.tsim.org.tw/.</Citation></Reference><Reference><Citation>Mensah PB, Quao NS, Dagadu S, et al. Can large language models provide emergency medical help where there is no ambulance? A comparative study on large language model understanding of emergency medical scenarios in resource-constrained settings. medRxiv 2024. doi:10.1101/2024.04.17.24305971</Citation><ArticleIdList><ArticleId IdType="doi">10.1101/2024.04.17.24305971</ArticleId></ArticleIdList></Reference><Reference><Citation>Uppalapati V, Nag D. A comparative analysis of AI models in complex medical decision-making scenarios: evaluating ChatGPT, Claude AI, Bard, and Perplexity. Cureus 2024; 16: e52485.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10874112</ArticleId><ArticleId IdType="pubmed">38371109</ArticleId></ArticleIdList></Reference><Reference><Citation>Kurokawa R, Ohizumi Y, Kanzawa J, et al. Diagnostic performance of Claude 3 from patient history and key images in diagnosis please cases. medRxiv 2024. doi:10.1101/2024.04.11.24305622</Citation><ArticleIdList><ArticleId IdType="doi">10.1101/2024.04.11.24305622</ArticleId><ArticleId IdType="pubmed">39096483</ArticleId></ArticleIdList></Reference><Reference><Citation>Venerito V, Fornaro M, Sabbagh S, et al. Integrating large language models in medicine: a study of Claude 2's performance in MDAAT scoring for idiopathic inflammatory myopathies. Rheumatology (Oxford) 2024; 63(10): e292–e293.</Citation><ArticleIdList><ArticleId IdType="pubmed">38648744</ArticleId></ArticleIdList></Reference><Reference><Citation>Wu S, Koo M, Blum L, et al. Benchmarking open-source large language models, GPT-4o and Claude 2 on multiple-choice questions in nephrology. NEJM AI 2024; 1(2). doi:10.1056/AIdbp2300092</Citation><ArticleIdList><ArticleId IdType="doi">10.1056/AIdbp2300092</ArticleId></ArticleIdList></Reference><Reference><Citation>Abbas A, Rehman MS, Rehman SS. Comparing the performance of popular large language models on the national board of medical examiners sample questions. Cureus 2024; 16: e55991.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC11007479</ArticleId><ArticleId IdType="pubmed">38606229</ArticleId></ArticleIdList></Reference><Reference><Citation>Huang SS, Song Q, Beiting KJ, et al. Fact check: assessing the response of ChatGPT to Alzheimer’s disease statements with varying degrees of misinformation. Medrxiv 2024. doi:10.1101/2023.09.04.23294917</Citation><ArticleIdList><ArticleId IdType="doi">10.1101/2023.09.04.23294917</ArticleId><ArticleId IdType="pubmed">39106968</ArticleId></ArticleIdList></Reference><Reference><Citation>Inojosa H, Gilbert S, Kather JN, et al. Can ChatGPT explain it? Use of artificial intelligence in multiple sclerosis communication. Neurol Res Pract 2023; 5: 48.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10469796</ArticleId><ArticleId IdType="pubmed">37649106</ArticleId></ArticleIdList></Reference><Reference><Citation>Kim H-W, Shin D-H, Kim J, et al. Assessing the performance of ChatGPT's responses to questions related to epilepsy: a cross-sectional study on natural language processing and medical information retrieval. Seizure 2024; 114: 1–8.</Citation><ArticleIdList><ArticleId IdType="pubmed">38007922</ArticleId></ArticleIdList></Reference><Reference><Citation>Jin H, Zhang Y, Meng D, et al. A comprehensive survey on process-oriented automatic text summarization with exploration of LLM-based methods. arXiv. 2024; preprint arXiv:2403.02901.</Citation></Reference><Reference><Citation>Huang Y, Tang K, Chen M. Leveraging large language models for enhanced NLP task performance through knowledge distillation and optimized training strategies. arXiv. 2024; preprint arXiv:2402.09282.</Citation></Reference><Reference><Citation>Gao M, Hu X, Ruan J, et al. LLM-based NLG evaluation: current status and challenges. arXiv. 2024; preprint arXiv:2402.01383.</Citation></Reference><Reference><Citation>Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need. arXiv. 2017; arXiv:1706.03762.</Citation></Reference><Reference><Citation>OpenAI. https://www.openai.com/research/.</Citation></Reference><Reference><Citation>Ia G. Deep learning. An MIT press book. Ian Goodfellow and Yoshua Bengio and Aaron Courville, 2016. Cambridge, MA.</Citation></Reference><Reference><Citation>Yun Y, Kim J. CIC: a framework for culturally-aware image captioning. arXiv. 2024; preprint arXiv:2402.05374.</Citation></Reference><Reference><Citation>Lyu C, Wu M, Wang L, et al.. Macaw-LLM: multi-modal language modeling with image, audio, video, and text integration. arXiv. 2023; preprint arXiv:2306.09093.</Citation></Reference><Reference><Citation>Lang O, Yaya-Stupp D, Traynis I, et al. Using generative AI to investigate medical imagery models and datasets. EBioMedicine 2024; 102: 105075.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC10993140</ArticleId><ArticleId IdType="pubmed">38565004</ArticleId></ArticleIdList></Reference><Reference><Citation>Ciotti M, Ciccozzi M, Terrinoni A, et al. The COVID-19 pandemic. Crit Rev Clin Lab Sci 2020; 57: 365–388.</Citation><ArticleIdList><ArticleId IdType="pubmed">32645276</ArticleId></ArticleIdList></Reference></ReferenceList></PubmedData></PubmedArticle>