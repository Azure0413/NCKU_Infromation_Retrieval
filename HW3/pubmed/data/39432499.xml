<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">39432499</PMID><DateCompleted><Year>2024</Year><Month>10</Month><Day>21</Day></DateCompleted><DateRevised><Year>2024</Year><Month>10</Month><Day>25</Day></DateRevised><Article PubModel="Print"><Journal><ISSN IssnType="Electronic">1758-0463</ISSN><JournalIssue CitedMedium="Internet"><Volume>2024</Volume><PubDate><Year>2024</Year><Month>Oct</Month><Day>21</Day></PubDate></JournalIssue><Title>Database : the journal of biological databases and curation</Title><ISOAbbreviation>Database (Oxford)</ISOAbbreviation></Journal><ArticleTitle>Is metadata of articles about COVID-19 enough for multilabel topic classification task?</ArticleTitle><ELocationID EIdType="pii" ValidYN="Y">baae106</ELocationID><ELocationID EIdType="doi" ValidYN="Y">10.1093/database/baae106</ELocationID><Abstract><AbstractText>The ever-increasing volume of COVID-19-related articles presents a significant challenge for the manual curation and multilabel topic classification of LitCovid. For this purpose, a novel multilabel topic classification framework is developed in this study, which considers both the correlation and imbalance of topic labels, while empowering the pretrained model. With the help of this framework, this study devotes to answering the following question: Do full texts, MeSH (Medical Subject Heading), and biological entities of articles about COVID-19 encode more discriminative information than metadata (title, abstract, keyword, and journal name)? From extensive experiments on our enriched version of the BC7-LitCovid corpus and Hallmarks of Cancer corpus, the following conclusions can be drawn. Our framework demonstrates superior performance and robustness. The metadata of scientific publications about COVID-19 carries valuable information for multilabel topic classification. Compared to biological entities, full texts and MeSH can further enhance the performance of our framework for multilabel topic classification, but the improved performance is very limited. Database URL: https://github.com/pzczxs/Enriched-BC7-LitCovid.</AbstractText><CopyrightInformation>© The Author(s) 2024. Published by Oxford University Press.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Xu</LastName><ForeName>Shuo</ForeName><Initials>S</Initials><Identifier Source="ORCID">0000-0002-8602-1819</Identifier><AffiliationInfo><Affiliation>College of Economics and Management, Beijing University of Technology, No. 100 PingLeYuan, Chaoyang District, Beijing 100124, P.R. China.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Zhang</LastName><ForeName>Yuefu</ForeName><Initials>Y</Initials><AffiliationInfo><Affiliation>College of Economics and Management, Beijing University of Technology, No. 100 PingLeYuan, Chaoyang District, Beijing 100124, P.R. China.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Chen</LastName><ForeName>Liang</ForeName><Initials>L</Initials><Identifier Source="ORCID">0000-0002-3235-9806</Identifier><AffiliationInfo><Affiliation>Institute of Scientific and Technical Information of China, No. 15 Fuxing Road, Haidian District, Beijing 100038, P.R. China.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>An</LastName><ForeName>Xin</ForeName><Initials>X</Initials><AffiliationInfo><Affiliation>School of Economics and Management, Beijing Forestry University, No. 35 Qinghua East Road, Haidian District, Beijing 100083, P.R. China.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><GrantList CompleteYN="Y"><Grant><GrantID>72004012 72074014</GrantID><Agency>National Natural Science Foundation of China</Agency><Country /></Grant><Grant><GrantID>72004012 72074014</GrantID><Agency>National Natural Science Foundation of China</Agency><Country /></Grant></GrantList><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>Database (Oxford)</MedlineTA><NlmUniqueID>101517697</NlmUniqueID><ISSNLinking>1758-0463</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000086382" MajorTopicYN="Y">COVID-19</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000071253" MajorTopicYN="Y">Metadata</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000086402" MajorTopicYN="Y">SARS-CoV-2</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D046650" MajorTopicYN="N">Medical Subject Headings</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D066289" MajorTopicYN="N">Data Curation</DescriptorName><QualifierName UI="Q000379" MajorTopicYN="N">methods</QualifierName></MeshHeading></MeshHeadingList><CoiStatement>None declared.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2023</Year><Month>10</Month><Day>25</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2024</Year><Month>6</Month><Day>3</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>9</Month><Day>12</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>10</Month><Day>21</Day><Hour>22</Hour><Minute>21</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>10</Month><Day>21</Day><Hour>22</Hour><Minute>20</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>10</Month><Day>21</Day><Hour>13</Hour><Minute>36</Minute></PubMedPubDate><PubMedPubDate PubStatus="pmc-release"><Year>2024</Year><Month>10</Month><Day>21</Day></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39432499</ArticleId><ArticleId IdType="pmc">PMC11492800</ArticleId><ArticleId IdType="doi">10.1093/database/baae106</ArticleId><ArticleId IdType="pii">7828987</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Chen Q, Allot A, Lu Z. LitCovid: an open database of COVID-19 literature. Nucleic Acids Res 2021;49:D1534–D1540. doi: 10.1093/nar/gkaa952</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/nar/gkaa952</ArticleId><ArticleId IdType="pmc">PMC7778958</ArticleId><ArticleId IdType="pubmed">33166392</ArticleId></ArticleIdList></Reference><Reference><Citation>Chen Q, Allot A, Lu Z. Keep up with the latest coronavirus research. Nature 2020;579:193–94. doi: 10.1038/d41586-020-00694-1</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/d41586-020-00694-1</ArticleId><ArticleId IdType="pubmed">32157233</ArticleId></ArticleIdList></Reference><Reference><Citation>Chen Q, Allot A, Leaman R. et al. LitCovid in 2022: an information resource for the COVID-19 literature. Nucleic Acids Res 2023;51:D1512–D1518. doi: 10.1093/nar/gkac1005</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/nar/gkac1005</ArticleId><ArticleId IdType="pmc">PMC9825538</ArticleId><ArticleId IdType="pubmed">36350613</ArticleId></ArticleIdList></Reference><Reference><Citation>Chen Q, Allot A, Leaman R. et al. Multi-label classification for biomedical literature: an overview of the BioCreative VII LitCovid Track for COVID-19 literature topic annotations. Database 2022:baac069. doi: 10.1093/database/baac069</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/database/baac069</ArticleId><ArticleId IdType="pmc">PMC9428574</ArticleId><ArticleId IdType="pubmed">36043400</ArticleId></ArticleIdList></Reference><Reference><Citation>Chen Q, Du J, Allot A. et al. LitMC-BERT: transformer-based multi-label classification of biomedical literature with an application on COVID-19 literature curation. IEEE/ACM Trans Comput Biol Bioinform 2022;19:2584–95. doi: 10.1109/TCBB.2022.3173562</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/TCBB.2022.3173562</ArticleId><ArticleId IdType="pmc">PMC9647722</ArticleId><ArticleId IdType="pubmed">35536809</ArticleId></ArticleIdList></Reference><Reference><Citation>Devlin J, Chang MW, Lee K. et al. Bert: pre-training of deep bidirectional transformers for language understanding. arXiv preprint, arXiv:1810.04805. 2018.</Citation></Reference><Reference><Citation>Lee J, Yoon W, Kim S. et al. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics 2020;36:1234–40. doi: 10.1093/bioinformatics/btz682</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/bioinformatics/btz682</ArticleId><ArticleId IdType="pmc">PMC7703786</ArticleId><ArticleId IdType="pubmed">31501885</ArticleId></ArticleIdList></Reference><Reference><Citation>Gu Y, Tinn R, Cheng H. et al. Domain-specific language model pretraining for biomedical natural language processing. ACM Trans Comput Healthc 2021;3:1–23. doi: 10.1145/3458754</Citation><ArticleIdList><ArticleId IdType="doi">10.1145/3458754</ArticleId></ArticleIdList></Reference><Reference><Citation>Xu S, An X. ML2S-SVM: multi-label least-squares support vector machine classifiers. Electron Libr 2019;37:1040–58. doi: 10.1108/EL-09-2019-0207</Citation><ArticleIdList><ArticleId IdType="doi">10.1108/EL-09-2019-0207</ArticleId></ArticleIdList></Reference><Reference><Citation>Gu J, Chersoni E, Wang X. et al. LitCovid ensemble learning for COVID-19 multi-label classification. Database 2022:baac103. doi: 10.1093/database/baac103</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/database/baac103</ArticleId><ArticleId IdType="pmc">PMC9693804</ArticleId><ArticleId IdType="pubmed">36426767</ArticleId></ArticleIdList></Reference><Reference><Citation>Lin SJ, Yeh WC, Chiu YW. et al. A BERT-based ensemble learning approach for the BioCreative VII challenges: full-text chemical identification and multi-label classification in PubMed articles. Database 2022:baac056. doi: 10.1093/database/baac056</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/database/baac056</ArticleId><ArticleId IdType="pmc">PMC9290865</ArticleId><ArticleId IdType="pubmed">35849027</ArticleId></ArticleIdList></Reference><Reference><Citation>Tang W, Wang J, Zhang H. et al. Team DUT914 at BioCreative VII LitCovid Track: A BioBERT-based feature enhancement approach. In: Proceedings of the BioCreative VII Challenge Evaluation Workshop, pp. 292–294. USA: BioCreative, Cecilia Arighi, University of Delaware, 2021.</Citation></Reference><Reference><Citation>Madjarov G, Kocev D, Gjorgjevikj D. et al. An extensive experimental comparison of methods for multi-label learning. Pattern Recognit 2012;45:3084–104. doi: 10.1016/j.patcog.2012.03.004</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.patcog.2012.03.004</ArticleId></ArticleIdList></Reference><Reference><Citation>Li T, and Ogihara M. Detecting emotion in music. In: Proceedings of the 4th International Conference on Music Information Retrieval. Baltimore, MD: The International Society for Music Information Retrieval, 2003.</Citation></Reference><Reference><Citation>Read J, Pfahringer B, Holmes G. et al. Classifier chains for multi-label classification. Mach Learn 2011;85:333–59. doi: 10.1007/s10994-011-5256-5</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/s10994-011-5256-5</ArticleId></ArticleIdList></Reference><Reference><Citation>Fürnkranz J, and Hüllermeier E. Pairwise preference learning and ranking. In: Proceedings of European Conference on Machine Learning. Berlin and Heidelberg: Springer, pp. 145–56, 2003.</Citation></Reference><Reference><Citation>Zhang ML, and Zhang K. Multi-label learning by exploiting label dependency. In: Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. New York: Association for Computing Machinery, pp. 999–1008, 2010.</Citation></Reference><Reference><Citation>Fürnkranz J, Hüllermeier E, Loza Mencía E. et al. Multilabel classification via calibrated label ranking. Mach Learn 2008;73:133–53. doi: 10.1007/s10994-008-5064-8</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/s10994-008-5064-8</ArticleId></ArticleIdList></Reference><Reference><Citation>Read J, Martino L, Olmos PM. et al. Scalable multi-output label prediction: from classifier chains to classifier trellises. Pattern Recognit 2015;48:2096–109. doi: 10.1016/j.patcog.2015.01.004</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.patcog.2015.01.004</ArticleId></ArticleIdList></Reference><Reference><Citation>Clare A, and King RD. Knowledge discovery in multi-label phenotype data. In: Proceedings of European Conference on Principles of Data Mining and Knowledge discovery. Berlin, Heidelberg: Springer, pp. 42–53, 2001.</Citation></Reference><Reference><Citation>Schapire RE. A brief introduction to boosting. In: Proceedings of the 16th International Joint Conference on Artificial Intelligence, Vol. 99, pp. 1401–06. San Francisco, CA: Morgan Kaufmann Publishers Inc., 1999.</Citation></Reference><Reference><Citation>Zhang ML, Zhou ZH. ML-KNN: a lazy learning approach to multi-label learning. Pattern Recognit 2007;40:2038–48. doi: 10.1016/j.patcog.2006.12.019</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.patcog.2006.12.019</ArticleId></ArticleIdList></Reference><Reference><Citation>Elisseeff A, and Weston J. A kernel method for multi-labelled classification. In: Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic. Cambridge, MA: MIT Press, pp. 681–7, 2001.</Citation></Reference><Reference><Citation>Zhang ML, Zhou ZH. Multilabel neural networks with applications to functional genomics and text categorization. IEEE Trans Knowl Data Eng 2006;18:1338–51. doi: 10.1109/TKDE.2006.162</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/TKDE.2006.162</ArticleId></ArticleIdList></Reference><Reference><Citation>Kim Y. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882. 2014.</Citation></Reference><Reference><Citation>Zhou P, Shi W, Tian J. et al. Attention-based bidirectional long short-term memory networks for relation classification. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Berlin: Association for Computational Linguistics, Vol. 2, pp. 207–12, 2016.</Citation></Reference><Reference><Citation>Haghighian Roudsari A, Afshar J, Lee W. et al. PatentNet: multi-label classification of patent documents using deep learning based language understanding. Scientometrics 2022;127:207–31.</Citation></Reference><Reference><Citation>Fang L, Chen Q, Wei CH. et al. Bioformer: an efficient transformer language model for biomedical text mining. arXiv preprint, arXiv:2302.01588. 2023.</Citation></Reference><Reference><Citation>Xu S, Zhang Y, and An X. Team BJUT-BJFU at BioCreative VII LitCovid Track: A deep learning based method for multi-label topic classification in COVID-19 literature. In: Proceedings of the BioCreative VII Challenge Evaluation Workshop. USA: BioCreative, Cecilia Arighi, University of Delaware, pp. 275–77, 2021.</Citation></Reference><Reference><Citation>Joulin A, Grave E, Bojanowski P. et al. Fasttext. zip: compressing text classification models. arXiv preprint, arXiv:1612.03651. 2016.</Citation></Reference><Reference><Citation>Xu S, Zhang Y, An X. et al. Performance evaluation of seven multi-label classification methods on real-world patent and publication datasets. J Data Inf Sci 2024;9:81–103.</Citation></Reference><Reference><Citation>Yu Z, Hao H, Zhang W. et al. A classifier chain algorithm with k-means for multi-label classification on clouds. J Signal Process Syst 2017;86:337–46. doi: 10.1007/s11265-016-1137-2</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/s11265-016-1137-2</ArticleId></ArticleIdList></Reference><Reference><Citation>Freitas Rocha V, Varejão FM, and Segatto MEV. Ensemble of classifier chains and decision templates for multi-label classification. Knowl Inf Syst 2022;64:643–63.</Citation></Reference><Reference><Citation>Read J, Pfahringer B, and Holmes G. Multi-label classification using ensembles of pruned sets. In: Proceedings of the 2008 eighth IEEE International Conference on Data Mining. pp. 995–1000. Washington, DC: IEEE, 2008.</Citation></Reference><Reference><Citation>Tsoumakas G, Katakis I, Vlahavas I. Random k-labelsets for multilabel classification. IEEE Trans Knowl Data Eng 2011;23:1079–89. doi: 10.1109/TKDE.2010.164</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/TKDE.2010.164</ArticleId></ArticleIdList></Reference><Reference><Citation>Zhang ML, Zhou ZH. A review on multi-label learning algorithms. IEEE Trans Knowl Data Eng 2013;26:1819–37. doi: 10.1109/TKDE.2013.39</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/TKDE.2013.39</ArticleId></ArticleIdList></Reference><Reference><Citation>Xu S, Ma F, and Tao L. Learn from the information contained in the false splice sites as well as in the true splice sites using SVM. Proceedings of International Conference on Intelligent Systems and Knowledge Engineering 2007. pp. 65–71. Chengdu: Atlantis Press, 2007.</Citation></Reference><Reference><Citation>Bagherzadeh P, and Bergler S. CLaC at BioCreative VII LitCovid Track: Independent modules for multi-label classification of Covid articles. In: Proceedings of the BioCreative VII Challenge Evaluation Workshop, Cecilia Arighi, University of Delaware. pp. 278–82. USA: BioCreative, 2021.</Citation></Reference><Reference><Citation>Xu S, Hao L, An X. et al. Types of DOI errors of cited references in web of science with a cleaning method. Scientometrics 2019;120:1427–37. doi: 10.1007/s11192-019-03162-4</Citation><ArticleIdList><ArticleId IdType="doi">10.1007/s11192-019-03162-4</ArticleId></ArticleIdList></Reference><Reference><Citation>Comeau DC, Islamaj Doğan R, Ciccarese P. et al. BioC: a minimalist approach to interoperability for biomedical text processing. Database 2013:bat064. doi: 10.1093/database/bat064</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/database/bat064</ArticleId><ArticleId IdType="pmc">PMC3889917</ArticleId><ArticleId IdType="pubmed">24048470</ArticleId></ArticleIdList></Reference><Reference><Citation>Beltagy I, Peters ME, Cohan A. Longformer: the long-document transformer. arXiv preprint, arXiv:2004.05150. 2020.</Citation></Reference><Reference><Citation>Xu S, An X, Zhu L. et al. A CRF-based system for recognizing chemical entity mentions (CEMs) in biomedical literature. J Cheminf 2015;7:1–9. doi: 10.1186/1758-2946-7-S1-S11</Citation><ArticleIdList><ArticleId IdType="doi">10.1186/1758-2946-7-S1-S11</ArticleId><ArticleId IdType="pmc">PMC4331687</ArticleId><ArticleId IdType="pubmed">25810768</ArticleId></ArticleIdList></Reference><Reference><Citation>Wei CH, Allot A, Leaman R. et al. PubTator central: automated concept annotation for biomedical full text articles. Nucleic Acids Res 2019;47:W587–W593. doi: 10.1093/nar/gkz389</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/nar/gkz389</ArticleId><ArticleId IdType="pmc">PMC6602571</ArticleId><ArticleId IdType="pubmed">31114887</ArticleId></ArticleIdList></Reference><Reference><Citation>Mork JG, Jimeno-Yepes A, and Aronson AR. The NLM medical text indexer system for indexing biomedical literature. In: Proceedings of the first Workshop on Bio-Medical Semantic Indexing and Question Answering, a Post-Conference Workshop of Conference and Labs of the Evaluation Forum 2013 (CLEF 2013). CEUR Workshop Proceedings, Valencia, Spain, September 27, 2013.</Citation></Reference><Reference><Citation>Luo ZH, Shi MW, Yang Z. et al. pyMeSHSim: an integrative python package for biomedical named entity recognition, normalization, and comparison of MeSH terms. BMC Bioinf 2020;21:1–14. doi: 10.1186/s12859-020-03583-6</Citation><ArticleIdList><ArticleId IdType="doi">10.1186/s12859-020-03583-6</ArticleId><ArticleId IdType="pmc">PMC7301509</ArticleId><ArticleId IdType="pubmed">32552728</ArticleId></ArticleIdList></Reference><Reference><Citation>Peng S, You R, Wang H. et al. DeepMeSH: deep semantic representation for improving large-scale MeSH indexing. Bioinformatics 2016;32:i70–i79. doi: 10.1093/bioinformatics/btw294</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/bioinformatics/btw294</ArticleId><ArticleId IdType="pmc">PMC4908368</ArticleId><ArticleId IdType="pubmed">27307646</ArticleId></ArticleIdList></Reference><Reference><Citation>Tsoumakas G, and Vlahavas I. Random k-labelsets: an ensemble method for multilabel classification. In: Proceedings of European Conference on Machine Learning. pp. 406–17. Berlin and Heidelberg: Springer, 2007.</Citation></Reference><Reference><Citation>Khushaba RN, Al-Ani A, Al-Jumaily A. Feature subset selection using differential evolution and a statistical repair mechanism. Expert Syst Appl 2011;38:11515–26. doi: 10.1016/j.eswa.2011.03.028</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.eswa.2011.03.028</ArticleId></ArticleIdList></Reference><Reference><Citation>Mikolov T, Chen K, Corrado G. et al. Efficient estimation of word representations in vector space. arXiv preprint, arXiv:1301.3781. 2013.</Citation></Reference><Reference><Citation>Pennington J, Socher R, and Manning CD. Glove: global vectors for word representation. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1532–43. Doha: Association for Computational Linguistics, 2014.</Citation></Reference><Reference><Citation>Zhu Y, Kiros R, Zemel R. et al. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 19–27. NW Washington, DC: IEEE Computer Society, 2015.</Citation></Reference><Reference><Citation>Liu Y, Ott M, Goyal N. et al. Roberta: A robustly optimized Bert pretraining approach. arXiv preprint, arXiv:1907.11692. 2019.</Citation></Reference><Reference><Citation>Tsoumakas G, Katakis I. Multi-label classification: an overview international journal of data warehousing and mining. Int J Data Warehous Min 2007;3. doi: 10.4018/jdwm.2007070101</Citation><ArticleIdList><ArticleId IdType="doi">10.4018/jdwm.2007070101</ArticleId></ArticleIdList></Reference><Reference><Citation>
Hsu CW, Chang CC, Lin CJ. A Practical Guide to Support Vector Classification. 2003. https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf (2 December 2022, date last accessed).</Citation></Reference><Reference><Citation>Hsu CW, Lin CJ. A comparison of methods for multiclass support vector machines. IEEE Trans Neural Netw 2002;13:415–25. doi: 10.1109/72.991427</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/72.991427</ArticleId><ArticleId IdType="pubmed">18244442</ArticleId></ArticleIdList></Reference><Reference><Citation>Du J, Chen Q, Peng Y. et al. ML-net: multi-label classification of biomedical texts with deep neural networks. J Am Med Inform Assoc 2019;26:1279–85. doi: 10.1093/jamia/ocz085</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/jamia/ocz085</ArticleId><ArticleId IdType="pmc">PMC7647240</ArticleId><ArticleId IdType="pubmed">31233120</ArticleId></ArticleIdList></Reference><Reference><Citation>Fang L, and Wang K. Team Bioformer at BioCreative VII LitCovid Track: multic-label topic classification for COVID-19 literature with a compact BERT model. In: Proceedings of the 7th BioCreative Challenge Evaluation Workshop, USA: BioCreative, Cecilia Arighi, University of Delaware, pp. 272–74. 2021.</Citation></Reference><Reference><Citation>Baker S, Silins I, Guo Y. et al. Automatic semantic classification of scientific literature according to the hallmarks of cancer. Bioinformatics 2016;32:432–40. doi: 10.1093/bioinformatics/btv585</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/bioinformatics/btv585</ArticleId><ArticleId IdType="pubmed">26454282</ArticleId></ArticleIdList></Reference><Reference><Citation>Weber L, Sänger M, Münchmeyer J. et al. HunFlair: an easy-to-use tool for state-of-the-art biomedical named entity recognition. Bioinformatics 2021;37:2792–94. doi: 10.1093/bioinformatics/btab042</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/bioinformatics/btab042</ArticleId><ArticleId IdType="pmc">PMC8428609</ArticleId><ArticleId IdType="pubmed">33508086</ArticleId></ArticleIdList></Reference><Reference><Citation>Wang LL, Lo L, Chandrasekhar Y. et al. CORD-19: The COVID-19 open research dataset. In: Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020. Association for Computational Linguistics, Online. 2020.</Citation></Reference><Reference><Citation>An X, Zhang M, Xu S. An active learning based approach for screening scholarly articles about the origins of SARS-CoV-2. PLoS One 2022;17:e0273725. doi: 10.1371/journal.pone.0273725</Citation><ArticleIdList><ArticleId IdType="doi">10.1371/journal.pone.0273725</ArticleId><ArticleId IdType="pmc">PMC9480989</ArticleId><ArticleId IdType="pubmed">36112646</ArticleId></ArticleIdList></Reference><Reference><Citation>Munkhdalai T, Faruqui M, Gopal S. Leave no context behind: efficient infinite context transformers with infini-attention. arXiv preprint, arXiv:2404.07143. 2024.</Citation></Reference></ReferenceList></PubmedData></PubmedArticle>