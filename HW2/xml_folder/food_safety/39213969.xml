<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">39213969</PMID><DateCompleted><Year>2024</Year><Month>09</Month><Day>12</Day></DateCompleted><DateRevised><Year>2024</Year><Month>09</Month><Day>12</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1873-7072</ISSN><JournalIssue CitedMedium="Internet"><Volume>462</Volume><PubDate><Year>2025</Year><Month>Jan</Month><Day>01</Day></PubDate></JournalIssue><Title>Food chemistry</Title><ISOAbbreviation>Food Chem</ISOAbbreviation></Journal><ArticleTitle>Smartphone video imaging: A versatile, low-cost technology for food authentication.</ArticleTitle><Pagination><StartPage>140911</StartPage><MedlinePgn>140911</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1016/j.foodchem.2024.140911</ELocationID><ELocationID EIdType="pii" ValidYN="Y">S0308-8146(24)02561-5</ELocationID><Abstract><AbstractText>This study presents a low-cost smartphone-based imaging technique called smartphone video imaging (SVI) to capture short videos of samples that are illuminated by a colour-changing screen. Assisted by artificial intelligence, the study develops new capabilities to make SVI a versatile imaging technique such as the hyperspectral imaging (HSI). SVI enables classification of samples with heterogeneous contents, spatial representation of analyte contents and reconstruction of hyperspectral images from videos. When integrated with a residual neural network, SVI outperforms traditional computer vision methods for ginseng classification. Moreover, the technique effectively maps the spatial distribution of saffron purity in powder mixtures with predictive performance that is comparable to that of HSI. In addition, SVI combined with the U-Net deep learning module can produce high-quality images that closely resemble the target images acquired by HSI. These results suggest that SVI can serve as a consumer-oriented solution for food authentication.</AbstractText><CopyrightInformation>Copyright Â© 2024 Elsevier Ltd. All rights reserved.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Song</LastName><ForeName>Weiran</ForeName><Initials>W</Initials><AffiliationInfo><Affiliation>School of Food Science and Engineering, Hainan University, Haikou, 570228, China; State Key Laboratory of Power System Operation and Control, Department of Energy and Power Engineering, Tsinghua University, Beijing 100084, China.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Wang</LastName><ForeName>Hui</ForeName><Initials>H</Initials><AffiliationInfo><Affiliation>School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, Belfast BT9 5BN, UK.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Yun</LastName><ForeName>Yong-Huan</ForeName><Initials>YH</Initials><AffiliationInfo><Affiliation>School of Food Science and Engineering, Hainan University, Haikou, 570228, China. Electronic address: yunyonghuan@hainanu.edu.cn.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType><PublicationType UI="D023362">Evaluation Study</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2024</Year><Month>08</Month><Day>17</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>Food Chem</MedlineTA><NlmUniqueID>7702639</NlmUniqueID><ISSNLinking>0308-8146</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000068997" MajorTopicYN="Y">Smartphone</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000081862" MajorTopicYN="N">Hyperspectral Imaging</DescriptorName><QualifierName UI="Q000379" MajorTopicYN="N">methods</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D007091" MajorTopicYN="N">Image Processing, Computer-Assisted</DescriptorName><QualifierName UI="Q000379" MajorTopicYN="N">methods</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D005506" MajorTopicYN="N">Food Contamination</DescriptorName><QualifierName UI="Q000032" MajorTopicYN="N">analysis</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D014741" MajorTopicYN="N">Video Recording</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D005504" MajorTopicYN="N">Food Analysis</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">Computer vision</Keyword><Keyword MajorTopicYN="N">Food authentication</Keyword><Keyword MajorTopicYN="N">Hyperspectral imaging</Keyword><Keyword MajorTopicYN="N">Neural networks</Keyword><Keyword MajorTopicYN="N">Smartphone video imaging</Keyword><Keyword MajorTopicYN="N">Spectral reconstruction</Keyword></KeywordList><CoiStatement>Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>5</Month><Day>17</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2024</Year><Month>7</Month><Day>27</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>8</Month><Day>16</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>9</Month><Day>13</Day><Hour>0</Hour><Minute>46</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>8</Month><Day>31</Day><Hour>9</Hour><Minute>47</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>8</Month><Day>30</Day><Hour>18</Hour><Minute>9</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39213969</ArticleId><ArticleId IdType="doi">10.1016/j.foodchem.2024.140911</ArticleId><ArticleId IdType="pii">S0308-8146(24)02561-5</ArticleId></ArticleIdList></PubmedData></PubmedArticle>