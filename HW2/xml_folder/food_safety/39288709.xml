<PubmedArticle><MedlineCitation Status="Publisher" Owner="NLM"><PMID Version="1">39288709</PMID><DateRevised><Year>2024</Year><Month>09</Month><Day>17</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1873-4235</ISSN><JournalIssue CitedMedium="Internet"><Volume>267</Volume><PubDate><Year>2024</Year><Month>Sep</Month><Day>10</Day></PubDate></JournalIssue><Title>Biosensors &amp; bioelectronics</Title><ISOAbbreviation>Biosens Bioelectron</ISOAbbreviation></Journal><ArticleTitle>Supervised learning-based artificial senses for non-destructive fish quality classification.</ArticleTitle><Pagination><StartPage>116770</StartPage><MedlinePgn>116770</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1016/j.bios.2024.116770</ELocationID><ELocationID EIdType="pii" ValidYN="Y">S0956-5663(24)00776-0</ELocationID><Abstract><AbstractText>Human sensory techniques are inadequate for automating fish quality monitoring and maintaining controlled storage conditions throughout the supply chain. The dynamic monitoring of a single quality index cannot anticipate explicit freshness losses, which remarkably drops consumer acceptability. For the first time, a complete artificial sensory system is designed for the early detection of fish quality prediction. At non-isothermal storages, the rainbow trout quality is monitored by the gas sensors, texturometer, pH meter, camera, and TVB-N analysis. After data preprocessing, correlation analysis identifies the key parameters such as trimethylamine, ammonia, carbon dioxide, hardness, and adhesiveness to input into a back-propagation neural network. Using gas and textural key parameters, around 99 % prediction accuracy is achieved, precisely classifying fresh and spoiled classes. The regression analysis identifies a few gaps due to fewer datasets for model training, which can be reduced using few-shot learning techniques in the future. However, the multiparametric fusion of texture with gases enables early freshness loss detection and shows the capacity to automate the food supply chain completely.</AbstractText><CopyrightInformation>Copyright Â© 2024 Elsevier B.V. All rights reserved.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Saeed</LastName><ForeName>Rehan</ForeName><Initials>R</Initials><AffiliationInfo><Affiliation>Beijing Laboratory of Food Quality and Safety, College of Engineering, China Agricultural University, Beijing, 100083, PR China; Department of Automation, School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui, 230027, PR China.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Glamuzina</LastName><ForeName>Branko</ForeName><Initials>B</Initials><AffiliationInfo><Affiliation>Department of Aquaculture, University of Dubrovnik, 20000, Dubrovnik, Croatia.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Tuyet Nga</LastName><ForeName>Mai Thi</ForeName><Initials>MT</Initials><AffiliationInfo><Affiliation>Food Technology College, Nha Trang University, Nha Trang, Viet Nam.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Zhao</LastName><ForeName>Feng</ForeName><Initials>F</Initials><AffiliationInfo><Affiliation>Department of Automation, School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui, 230027, PR China. Electronic address: fzhao956@ustc.edu.cn.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Zhang</LastName><ForeName>Xiaoshuan</ForeName><Initials>X</Initials><AffiliationInfo><Affiliation>Beijing Laboratory of Food Quality and Safety, College of Engineering, China Agricultural University, Beijing, 100083, PR China; Sanya Institute, China Agricultural University, Sanya, 572024, PR China. Electronic address: zhxshuan@cau.edu.cn.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2024</Year><Month>09</Month><Day>10</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>Biosens Bioelectron</MedlineTA><NlmUniqueID>9001289</NlmUniqueID><ISSNLinking>0956-5663</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">Fish quality</Keyword><Keyword MajorTopicYN="N">Machine learning</Keyword><Keyword MajorTopicYN="N">Neural network</Keyword><Keyword MajorTopicYN="N">Sensor</Keyword><Keyword MajorTopicYN="N">Texture</Keyword></KeywordList><CoiStatement>Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2024</Year><Month>3</Month><Day>30</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2024</Year><Month>8</Month><Day>14</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2024</Year><Month>9</Month><Day>9</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2024</Year><Month>9</Month><Day>18</Day><Hour>0</Hour><Minute>51</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2024</Year><Month>9</Month><Day>18</Day><Hour>0</Hour><Minute>51</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2024</Year><Month>9</Month><Day>17</Day><Hour>18</Hour><Minute>7</Minute></PubMedPubDate></History><PublicationStatus>aheadofprint</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">39288709</ArticleId><ArticleId IdType="doi">10.1016/j.bios.2024.116770</ArticleId><ArticleId IdType="pii">S0956-5663(24)00776-0</ArticleId></ArticleIdList></PubmedData></PubmedArticle>